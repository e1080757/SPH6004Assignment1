{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ac3e891",
   "metadata": {},
   "source": [
    "Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485e7e4f",
   "metadata": {},
   "source": [
    "Genetic Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e98e56e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SVM SGDClassifier ###\n",
      "\n",
      "SMOTEN median noncontin\n",
      "\n",
      "Genetic Algorithm Feature Selection\n",
      "StandardScaler\n",
      "gen\tnevals\tfitness \tfitness_std\tfitness_max\tfitness_min\n",
      "0  \t50    \t0.633322\t0.0897003  \t0.700476   \t0.494578   \n",
      "1  \t100   \t0.689994\t0.0414969  \t0.700476   \t0.522575   \n",
      "2  \t100   \t0.683338\t0.0515721  \t0.700476   \t0.509155   \n",
      "3  \t100   \t0.686101\t0.0487871  \t0.700476   \t0.509012   \n",
      "4  \t100   \t0.686814\t0.0463423  \t0.700476   \t0.524513   \n",
      "5  \t100   \t0.679792\t0.0560624  \t0.700476   \t0.515732   \n",
      "6  \t100   \t0.673199\t0.0625117  \t0.700476   \t0.523624   \n",
      "7  \t100   \t0.679903\t0.0557278  \t0.700476   \t0.524851   \n",
      "8  \t100   \t0.690143\t0.040909   \t0.700476   \t0.526131   \n",
      "9  \t100   \t0.683227\t0.0517769  \t0.700476   \t0.522486   \n",
      "10 \t100   \t0.690188\t0.0407294  \t0.700476   \t0.525171   \n",
      "11 \t100   \t0.690132\t0.0409545  \t0.700476   \t0.52494    \n",
      "12 \t100   \t0.690011\t0.041424   \t0.700476   \t0.524868   \n",
      "13 \t100   \t0.687007\t0.0457042  \t0.700476   \t0.525633   \n",
      "14 \t100   \t0.690116\t0.0410344  \t0.700476   \t0.521349   \n",
      "15 \t100   \t0.690185\t0.0407385  \t0.700476   \t0.525971   \n",
      "16 \t100   \t0.686787\t0.0464409  \t0.700476   \t0.521687   \n",
      "17 \t100   \t0.6867  \t0.046724   \t0.700476   \t0.526113   \n",
      "18 \t100   \t0.690257\t0.0404555  \t0.700476   \t0.526646   \n",
      "19 \t100   \t0.676556\t0.0593538  \t0.700476   \t0.514985   \n",
      "20 \t100   \t0.686614\t0.0470218  \t0.700476   \t0.52302    \n",
      "21 \t100   \t0.683185\t0.0518955  \t0.700476   \t0.520833   \n",
      "22 \t100   \t0.690352\t0.0400757  \t0.700476   \t0.530699   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but GAFeatureSelectionCV was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimate',\n",
      "                 SGDClassifier(alpha=0.2001, validation_fraction=0.9))])\n",
      "\n",
      "Genetic Feature Selection: [False False  True False False False] \n",
      "\n",
      "classification report \n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Intubation False       0.65      0.82      0.72      6902\n",
      " Intubation True       0.77      0.57      0.65      7162\n",
      "\n",
      "        accuracy                           0.69     14064\n",
      "       macro avg       0.71      0.69      0.69     14064\n",
      "    weighted avg       0.71      0.69      0.69     14064\n",
      "\n",
      "Micro-averaged One-vs-Rest ROC AUC score:\n",
      "0.69\n",
      "\n",
      "\n",
      "RobustScaler\n",
      "gen\tnevals\tfitness \tfitness_std\tfitness_max\tfitness_min\n",
      "0  \t50    \t0.594872\t0.0974739  \t0.70053    \t0.494312   \n",
      "1  \t100   \t0.656387\t0.0783763  \t0.70053    \t0.501938   \n",
      "2  \t100   \t0.685004\t0.052178   \t0.701667   \t0.500622   \n",
      "3  \t100   \t0.689948\t0.0416543  \t0.701667   \t0.514754   \n",
      "4  \t100   \t0.677633\t0.0622772  \t0.701667   \t0.500036   \n",
      "5  \t100   \t0.684682\t0.0538027  \t0.701685   \t0.501013   \n",
      "6  \t100   \t0.667161\t0.0713385  \t0.701685   \t0.500782   \n",
      "7  \t100   \t0.69338 \t0.0354027  \t0.701685   \t0.519731   \n",
      "8  \t100   \t0.693091\t0.0369199  \t0.701685   \t0.502311   \n",
      "9  \t100   \t0.693581\t0.0353522  \t0.701881   \t0.515927   \n",
      "10 \t100   \t0.693518\t0.0354767  \t0.701881   \t0.518522   \n",
      "11 \t100   \t0.682517\t0.054932   \t0.701881   \t0.501049   \n",
      "12 \t100   \t0.697373\t0.0243319  \t0.701881   \t0.527108   \n",
      "13 \t100   \t0.689367\t0.0453221  \t0.701881   \t0.501742   \n",
      "14 \t100   \t0.6929  \t0.0383759  \t0.701881   \t0.501724   \n",
      "15 \t100   \t0.685771\t0.0510348  \t0.702325   \t0.501138   \n",
      "16 \t100   \t0.671337\t0.0676477  \t0.702325   \t0.505937   \n",
      "17 \t100   \t0.682304\t0.0549994  \t0.701472   \t0.499467   \n",
      "18 \t100   \t0.66346 \t0.0741253  \t0.701472   \t0.501938   \n",
      "19 \t100   \t0.686382\t0.047895   \t0.701472   \t0.502311   \n",
      "20 \t100   \t0.678869\t0.058516   \t0.701578   \t0.505315   \n",
      "21 \t100   \t0.677992\t0.0609659  \t0.701578   \t0.501742   \n",
      "22 \t100   \t0.685967\t0.0489364  \t0.701578   \t0.506879   \n",
      "best estimator Pipeline(steps=[('scaler', RobustScaler()),\n",
      "                ('estimate', SGDClassifier(alpha=0.1001, early_stopping=True))])\n",
      "\n",
      "Genetic Feature Selection: [ True  True  True  True  True  True] \n",
      "\n",
      "classification report \n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Intubation False       0.65      0.82      0.73      6902\n",
      " Intubation True       0.77      0.57      0.66      7162\n",
      "\n",
      "        accuracy                           0.69     14064\n",
      "       macro avg       0.71      0.70      0.69     14064\n",
      "    weighted avg       0.71      0.69      0.69     14064\n",
      "\n",
      "Micro-averaged One-vs-Rest ROC AUC score:\n",
      "0.70\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but GAFeatureSelectionCV was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn_genetic import *\n",
    "from sklearn_genetic.space import *\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, RidgeCV, LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "def myGAFeature(X, y, estimate, flag):\n",
    "    \n",
    "    model = lambda aPipe: Pipeline([('scaler',  aPipe), ('estimate', estimate)])\n",
    "    \n",
    "    cv = 2 \n",
    "    top_k = 1\n",
    "    dispatch = '4*n_jobs'\n",
    "    return_train = True\n",
    "    gen = 22\n",
    "    \n",
    "    def analyse(model):\n",
    "        geneSelectFeature = GAFeatureSelectionCV(estimator = model, cv=cv, \n",
    "                                                 scoring=None, population_size=50, \n",
    "                                                 generations=gen, crossover_probability=0.2, \n",
    "                                                 mutation_probability=0.8, tournament_size=3, \n",
    "                                                 elitism=True, max_features=None, verbose=True, \n",
    "                                                 keep_top_k=top_k, criteria='max', \n",
    "                                                 algorithm='eaMuPlusLambda', refit=True, \n",
    "                                                 n_jobs=4, \n",
    "                                                 pre_dispatch=dispatch, error_score=np.nan, \n",
    "                                                 return_train_score=return_train, log_config=None)\n",
    "\n",
    "        geneSelectFeature.fit(X_train, y_train)\n",
    "        y_pred = geneSelectFeature.predict(X_test)\n",
    "        print('best estimator ' + str(geneSelectFeature.best_estimator_))\n",
    "        print()\n",
    "        outcome_labels = ['Intubation False', 'Intubation True']\n",
    "        print('Genetic Feature Selection:', geneSelectFeature.support_, '\\n')\n",
    "        \n",
    "        print('classification report \\n', classification_report(y_test, y_pred, target_names=outcome_labels))\n",
    "        micro_roc_auc_ovr = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=\"micro\")\n",
    "        print(f\"Micro-averaged One-vs-Rest ROC AUC score:\\n{micro_roc_auc_ovr:.2f}\")\n",
    "        print('\\n')\n",
    "        return \"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0) #train split\n",
    "    \n",
    "    if flag == \"std\":\n",
    "        print('StandardScaler')\n",
    "        analyse(model(StandardScaler()))\n",
    "        \n",
    "    elif flag == \"rbt\":\n",
    "        print('RobustScaler')\n",
    "        analyse(model(RobustScaler()))\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "print('### SVM SGDClassifier ###')\n",
    "print()\n",
    "\n",
    "print('SMOTEN median noncontin')\n",
    "print()\n",
    "\n",
    "print('Genetic Algorithm Feature Selection')\n",
    "smoten_noncontin = pd.read_csv('smoten_noncontin.csv', index_col=False)\n",
    "smoten_noncontin = pd.read_csv('smoten_noncontin.csv', index_col=False)\n",
    "\n",
    "X = smoten_noncontin.drop('outcome',axis= 1)\n",
    "y = smoten_noncontin['outcome']\n",
    "\n",
    "\n",
    "best_paramsS =  {'estimate__alpha': 0.2001, 'estimate__validation_fraction': 0.9}\n",
    "best_paramsR =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.1}\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsS['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsS['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'std')\n",
    "\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsR['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsR['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'rbt')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "426d9b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SVM SGDClassifier ###\n",
      "\n",
      "SMOTEN median noncontin\n",
      "\n",
      "Genetic Algorithm Feature Selection\n",
      "StandardScaler\n",
      "gen\tnevals\tfitness \tfitness_std\tfitness_max\tfitness_min\n",
      "0  \t50    \t0.606699\t0.0940457  \t0.700565   \t0.483504   \n",
      "1  \t100   \t0.690032\t0.0413326  \t0.701241   \t0.519642   \n",
      "2  \t100   \t0.700597\t0.000457964\t0.702165   \t0.698788   \n",
      "3  \t100   \t0.697393\t0.0227804  \t0.702165   \t0.537952   \n",
      "4  \t100   \t0.686488\t0.0476527  \t0.702165   \t0.509812   \n",
      "5  \t100   \t0.689531\t0.0428139  \t0.702165   \t0.509812   \n",
      "6  \t100   \t0.686066\t0.0490267  \t0.700832   \t0.508159   \n",
      "7  \t100   \t0.682746\t0.0535142  \t0.702556   \t0.508355   \n",
      "8  \t100   \t0.680321\t0.0545677  \t0.702556   \t0.529757   \n",
      "9  \t100   \t0.683256\t0.051889   \t0.702556   \t0.519713   \n",
      "10 \t100   \t0.683058\t0.0528062  \t0.702556   \t0.51127    \n",
      "11 \t100   \t0.682937\t0.0532448  \t0.702556   \t0.516425   \n",
      "12 \t100   \t0.693705\t0.0338606  \t0.702556   \t0.524975   \n",
      "13 \t100   \t0.67599 \t0.0607442  \t0.701099   \t0.515554   \n",
      "14 \t100   \t0.693622\t0.0339253  \t0.701099   \t0.525437   \n",
      "15 \t100   \t0.700583\t0.00018341 \t0.701099   \t0.700476   \n",
      "16 \t100   \t0.693489\t0.0347883  \t0.702058   \t0.512105   \n",
      "17 \t100   \t0.683522\t0.0510411  \t0.702058   \t0.518878   \n",
      "18 \t100   \t0.669017\t0.0680232  \t0.702058   \t0.497689   \n",
      "19 \t100   \t0.690342\t0.0414033  \t0.702094   \t0.51918    \n",
      "20 \t100   \t0.694008\t0.0331737  \t0.702094   \t0.527855   \n",
      "21 \t100   \t0.683274\t0.0529205  \t0.702094   \t0.510079   \n",
      "22 \t100   \t0.686943\t0.0470851  \t0.702094   \t0.523198   \n",
      "best estimator Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimate',\n",
      "                 SGDClassifier(alpha=0.2001, early_stopping=True,\n",
      "                               validation_fraction=0.9))])\n",
      "\n",
      "Genetic Feature Selection: [ True  True  True False  True  True] \n",
      "\n",
      "classification report \n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Intubation False       0.65      0.82      0.72      6902\n",
      " Intubation True       0.77      0.57      0.65      7162\n",
      "\n",
      "        accuracy                           0.69     14064\n",
      "       macro avg       0.71      0.69      0.69     14064\n",
      "    weighted avg       0.71      0.69      0.69     14064\n",
      "\n",
      "Micro-averaged One-vs-Rest ROC AUC score:\n",
      "0.69\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but GAFeatureSelectionCV was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn_genetic import *\n",
    "from sklearn_genetic.space import *\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, RidgeCV, LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "def myGAFeature(X, y, estimate, flag):\n",
    "    \n",
    "    model = lambda aPipe: Pipeline([('scaler',  aPipe), ('estimate', estimate)])\n",
    "    \n",
    "    cv = 2 \n",
    "    top_k = 1\n",
    "    dispatch = '4*n_jobs'\n",
    "    return_train = True\n",
    "    gen = 22\n",
    "    \n",
    "    def analyse(model):\n",
    "        geneSelectFeature = GAFeatureSelectionCV(estimator = model, cv=cv, \n",
    "                                                 scoring=None, population_size=50, \n",
    "                                                 generations=gen, crossover_probability=0.2, \n",
    "                                                 mutation_probability=0.8, tournament_size=3, \n",
    "                                                 elitism=True, max_features=None, verbose=True, \n",
    "                                                 keep_top_k=top_k, criteria='max', \n",
    "                                                 algorithm='eaMuPlusLambda', refit=True, \n",
    "                                                 n_jobs=4, \n",
    "                                                 pre_dispatch=dispatch, error_score=np.nan, \n",
    "                                                 return_train_score=return_train, log_config=None)\n",
    "\n",
    "        geneSelectFeature.fit(X_train, y_train)\n",
    "        y_pred = geneSelectFeature.predict(X_test)\n",
    "        print('best estimator ' + str(geneSelectFeature.best_estimator_))\n",
    "        print()\n",
    "        outcome_labels = ['Intubation False', 'Intubation True']\n",
    "        print('Genetic Feature Selection:', geneSelectFeature.support_, '\\n')\n",
    "        \n",
    "        print('classification report \\n', classification_report(y_test, y_pred, target_names=outcome_labels))\n",
    "        micro_roc_auc_ovr = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=\"micro\")\n",
    "        print(f\"Micro-averaged One-vs-Rest ROC AUC score:\\n{micro_roc_auc_ovr:.2f}\")\n",
    "        print('\\n')\n",
    "        return \"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0) #train split\n",
    "    \n",
    "    if flag == \"std\":\n",
    "        print('StandardScaler')\n",
    "        analyse(model(StandardScaler()))\n",
    "        \n",
    "    elif flag == \"rbt\":\n",
    "        print('RobustScaler')\n",
    "        analyse(model(RobustScaler()))\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "print('### SVM SGDClassifier ###')\n",
    "print()\n",
    "\n",
    "print('SMOTEN median noncontin')\n",
    "print()\n",
    "\n",
    "print('Genetic Algorithm Feature Selection')\n",
    "smoten_noncontin = pd.read_csv('smoten_noncontin.csv', index_col=False)\n",
    "smoten_noncontin = pd.read_csv('smoten_noncontin.csv', index_col=False)\n",
    "\n",
    "X = smoten_noncontin.drop('outcome',axis= 1)\n",
    "y = smoten_noncontin['outcome']\n",
    "\n",
    "\n",
    "best_paramsS =  {'estimate__alpha': 0.2001, 'estimate__validation_fraction': 0.9}\n",
    "best_paramsR =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.1}\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsS['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsS['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'std')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78dcc993",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SVM SGDClassifier ###\n",
      "\n",
      "SMOTEN knn contin\n",
      "\n",
      "Genetic Algorithm Feature Selection\n",
      "StandardScaler\n",
      "gen\tnevals\tfitness \tfitness_std\tfitness_max\tfitness_min\n",
      "0  \t50    \t0.926045\t0.0194414  \t0.956414   \t0.875604   \n",
      "1  \t100   \t0.941935\t0.00871401 \t0.956129   \t0.924026   \n",
      "2  \t100   \t0.941802\t0.0100916  \t0.960342   \t0.915031   \n",
      "3  \t100   \t0.948813\t0.0085451  \t0.96068    \t0.925857   \n",
      "4  \t100   \t0.947895\t0.0134468  \t0.96068    \t0.902766   \n",
      "5  \t100   \t0.950743\t0.00984364 \t0.96068    \t0.923581   \n",
      "6  \t100   \t0.949923\t0.011331   \t0.96068    \t0.918373   \n",
      "7  \t100   \t0.94847 \t0.0150318  \t0.96068    \t0.897824   \n",
      "8  \t100   \t0.948068\t0.0164434  \t0.961977   \t0.896242   \n",
      "9  \t100   \t0.949808\t0.0140884  \t0.961977   \t0.911369   \n",
      "10 \t100   \t0.953459\t0.0111144  \t0.961977   \t0.91784    \n",
      "11 \t100   \t0.949909\t0.0140978  \t0.961977   \t0.904277   \n",
      "12 \t100   \t0.950454\t0.01222    \t0.961977   \t0.91848    \n",
      "13 \t100   \t0.95339 \t0.0110869  \t0.961977   \t0.90657    \n",
      "14 \t100   \t0.951423\t0.0110037  \t0.961977   \t0.921306   \n",
      "15 \t100   \t0.950236\t0.0144599  \t0.961977   \t0.910498   \n",
      "16 \t100   \t0.954835\t0.00963197 \t0.963293   \t0.9124     \n",
      "17 \t100   \t0.951092\t0.0152579  \t0.963293   \t0.901877   \n",
      "18 \t100   \t0.948748\t0.0172872  \t0.963293   \t0.901788   \n",
      "19 \t100   \t0.951519\t0.0142989  \t0.963293   \t0.893594   \n",
      "20 \t100   \t0.949986\t0.0142064  \t0.963293   \t0.907885   \n",
      "21 \t100   \t0.954286\t0.00774983 \t0.963293   \t0.928896   \n",
      "22 \t100   \t0.951614\t0.0125402  \t0.961711   \t0.904117   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but GAFeatureSelectionCV was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimate', SGDClassifier(early_stopping=True))])\n",
      "\n",
      "Genetic Feature Selection: [ True  True  True  True  True  True  True False False  True  True False\n",
      "  True  True  True  True  True  True False  True  True False  True False\n",
      "  True False  True  True] \n",
      "\n",
      "classification report \n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Intubation False       0.95      0.96      0.96      6902\n",
      " Intubation True       0.96      0.95      0.96      7162\n",
      "\n",
      "        accuracy                           0.96     14064\n",
      "       macro avg       0.96      0.96      0.96     14064\n",
      "    weighted avg       0.96      0.96      0.96     14064\n",
      "\n",
      "Micro-averaged One-vs-Rest ROC AUC score:\n",
      "0.96\n",
      "\n",
      "\n",
      "RobustScaler\n",
      "gen\tnevals\tfitness \tfitness_std\tfitness_max\tfitness_min\n",
      "0  \t50    \t0.935051\t0.0152895  \t0.956218   \t0.896082   \n",
      "1  \t100   \t0.949465\t0.00911589 \t0.960324   \t0.924595   \n",
      "2  \t100   \t0.950016\t0.0110576  \t0.960324   \t0.904224   \n",
      "3  \t100   \t0.947603\t0.013341   \t0.959364   \t0.90513    \n",
      "4  \t100   \t0.946104\t0.0137084  \t0.959382   \t0.909325   \n",
      "5  \t100   \t0.95134 \t0.00786878 \t0.959382   \t0.929305   \n",
      "6  \t100   \t0.950124\t0.0109389  \t0.959773   \t0.911654   \n",
      "7  \t100   \t0.95029 \t0.0118034  \t0.959773   \t0.9156     \n",
      "8  \t100   \t0.94802 \t0.0147267  \t0.959773   \t0.904366   \n",
      "9  \t100   \t0.950309\t0.0125109  \t0.962706   \t0.909539   \n",
      "10 \t100   \t0.952646\t0.010077   \t0.962706   \t0.916098   \n",
      "11 \t100   \t0.951287\t0.0106536  \t0.96164    \t0.922995   \n",
      "12 \t100   \t0.95233 \t0.00991583 \t0.96164    \t0.922302   \n",
      "13 \t100   \t0.952079\t0.0112128  \t0.96164    \t0.91784    \n",
      "14 \t100   \t0.950709\t0.0140365  \t0.962546   \t0.908703   \n",
      "15 \t100   \t0.952074\t0.0109346  \t0.962546   \t0.919529   \n",
      "16 \t100   \t0.949562\t0.0147628  \t0.961444   \t0.904224   \n",
      "17 \t100   \t0.952869\t0.0131518  \t0.961444   \t0.899406   \n",
      "18 \t100   \t0.955255\t0.0084712  \t0.96164    \t0.924986   \n",
      "19 \t100   \t0.956395\t0.00973078 \t0.961782   \t0.909059   \n",
      "20 \t100   \t0.95336 \t0.0130702  \t0.961657   \t0.905539   \n",
      "21 \t100   \t0.951898\t0.0144749  \t0.961871   \t0.897895   \n",
      "22 \t100   \t0.951422\t0.0160939  \t0.962262   \t0.883212   \n",
      "best estimator Pipeline(steps=[('scaler', RobustScaler()),\n",
      "                ('estimate',\n",
      "                 SGDClassifier(alpha=0.1001, early_stopping=True,\n",
      "                               validation_fraction=0.5))])\n",
      "\n",
      "Genetic Feature Selection: [ True False  True  True False  True  True  True False  True  True False\n",
      "  True False False  True  True  True  True  True False  True  True  True\n",
      "  True  True  True  True] \n",
      "\n",
      "classification report \n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Intubation False       0.95      0.97      0.96      6902\n",
      " Intubation True       0.97      0.95      0.96      7162\n",
      "\n",
      "        accuracy                           0.96     14064\n",
      "       macro avg       0.96      0.96      0.96     14064\n",
      "    weighted avg       0.96      0.96      0.96     14064\n",
      "\n",
      "Micro-averaged One-vs-Rest ROC AUC score:\n",
      "0.96\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but GAFeatureSelectionCV was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn_genetic import *\n",
    "from sklearn_genetic.space import *\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, RidgeCV, LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "def myGAFeature(X, y, estimate, flag):\n",
    "    \n",
    "    model = lambda aPipe: Pipeline([('scaler',  aPipe), ('estimate', estimate)])\n",
    "    \n",
    "    cv = 2 \n",
    "    top_k = 1\n",
    "    dispatch = '4*n_jobs'\n",
    "    return_train = True\n",
    "    gen = 22\n",
    "    \n",
    "    def analyse(model):\n",
    "        geneSelectFeature = GAFeatureSelectionCV(estimator = model, cv=cv, \n",
    "                                                 scoring=None, population_size=50, \n",
    "                                                 generations=gen, crossover_probability=0.2, \n",
    "                                                 mutation_probability=0.8, tournament_size=3, \n",
    "                                                 elitism=True, max_features=None, verbose=True, \n",
    "                                                 keep_top_k=top_k, criteria='max', \n",
    "                                                 algorithm='eaMuPlusLambda', refit=True, \n",
    "                                                 n_jobs=4, \n",
    "                                                 pre_dispatch=dispatch, error_score=np.nan, \n",
    "                                                 return_train_score=return_train, log_config=None)\n",
    "\n",
    "        geneSelectFeature.fit(X_train, y_train)\n",
    "        y_pred = geneSelectFeature.predict(X_test)\n",
    "        print('best estimator ' + str(geneSelectFeature.best_estimator_))\n",
    "        print()\n",
    "        outcome_labels = ['Intubation False', 'Intubation True']\n",
    "        print('Genetic Feature Selection:', geneSelectFeature.support_, '\\n')\n",
    "        \n",
    "        print('classification report \\n', classification_report(y_test, y_pred, target_names=outcome_labels))\n",
    "        micro_roc_auc_ovr = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=\"micro\")\n",
    "        print(f\"Micro-averaged One-vs-Rest ROC AUC score:\\n{micro_roc_auc_ovr:.2f}\")\n",
    "        print('\\n')\n",
    "        return \"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0) #train split\n",
    "    \n",
    "    if flag == \"std\":\n",
    "        print('StandardScaler')\n",
    "        analyse(model(StandardScaler()))\n",
    "        \n",
    "    elif flag == \"rbt\":\n",
    "        print('RobustScaler')\n",
    "        analyse(model(RobustScaler()))\n",
    "    return \"\"\n",
    "\n",
    "print('### SVM SGDClassifier ###')\n",
    "print()\n",
    "\n",
    "print('SMOTEN knn contin')\n",
    "print()\n",
    "\n",
    "print('Genetic Algorithm Feature Selection')\n",
    "smoten_knn_contin = pd.read_csv('smoten_knn_contin.csv', index_col=False)\n",
    "smoten_knn_contin = pd.read_csv('smoten_knn_contin.csv', index_col=False)\n",
    "\n",
    "X = smoten_knn_contin.drop('outcome',axis= 1)\n",
    "y = smoten_knn_contin['outcome']\n",
    "\n",
    "\n",
    "best_paramsS =  {'estimate__alpha': 0.0001, 'estimate__validation_fraction': 0.1}\n",
    "best_paramsR =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.5}\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsS['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsS['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'std')\n",
    "\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsR['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsR['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'rbt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a532bb57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SVM SGDClassifier ###\n",
      "\n",
      "SMOTEN median contin\n",
      "\n",
      "Genetic Algorithm Feature Selection\n",
      "StandardScaler\n",
      "gen\tnevals\tfitness\tfitness_std\tfitness_max\tfitness_min\n",
      "0  \t50    \t0.92915\t0.0206875  \t0.961231   \t0.86357    \n",
      "1  \t100   \t0.944163\t0.0114101  \t0.961231   \t0.913929   \n",
      "2  \t100   \t0.945014\t0.0115978  \t0.959827   \t0.908223   \n",
      "3  \t100   \t0.947303\t0.0124712  \t0.959933   \t0.910783   \n",
      "4  \t100   \t0.951802\t0.00825768 \t0.959933   \t0.923581   \n",
      "5  \t100   \t0.946112\t0.0171612  \t0.959702   \t0.898873   \n",
      "6  \t100   \t0.949646\t0.0113465  \t0.959702   \t0.91608    \n",
      "7  \t100   \t0.950477\t0.0104023  \t0.959702   \t0.91608    \n",
      "8  \t100   \t0.949344\t0.012552   \t0.960538   \t0.910801   \n",
      "9  \t100   \t0.948874\t0.0136922  \t0.960538   \t0.913449   \n",
      "10 \t100   \t0.950785\t0.0127753  \t0.960538   \t0.909752   \n",
      "11 \t100   \t0.951389\t0.0121619  \t0.960538   \t0.909752   \n",
      "12 \t100   \t0.952971\t0.0120995  \t0.960929   \t0.904526   \n",
      "13 \t100   \t0.950686\t0.015207   \t0.960929   \t0.900828   \n",
      "14 \t100   \t0.951163\t0.0147926  \t0.961373   \t0.908045   \n",
      "15 \t100   \t0.952933\t0.0138076  \t0.962173   \t0.914338   \n",
      "16 \t100   \t0.953584\t0.012696   \t0.961889   \t0.903655   \n",
      "17 \t100   \t0.951104\t0.0138672  \t0.961942   \t0.909343   \n",
      "18 \t100   \t0.955752\t0.0088626  \t0.961942   \t0.924772   \n",
      "19 \t100   \t0.950668\t0.0160904  \t0.961942   \t0.900615   \n",
      "20 \t100   \t0.956503\t0.00962936 \t0.962048   \t0.920862   \n",
      "21 \t100   \t0.95471 \t0.0116655  \t0.962084   \t0.912756   \n",
      "22 \t100   \t0.955132\t0.0128507  \t0.962084   \t0.902801   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but GAFeatureSelectionCV was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimate',\n",
      "                 SGDClassifier(alpha=0.1001, early_stopping=True,\n",
      "                               validation_fraction=0.7))])\n",
      "\n",
      "Genetic Feature Selection: [ True False  True  True  True False False  True False  True False False\n",
      "  True  True  True  True False  True  True  True  True  True  True  True\n",
      "  True  True  True  True] \n",
      "\n",
      "classification report \n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Intubation False       0.95      0.97      0.96      6902\n",
      " Intubation True       0.97      0.95      0.96      7162\n",
      "\n",
      "        accuracy                           0.96     14064\n",
      "       macro avg       0.96      0.96      0.96     14064\n",
      "    weighted avg       0.96      0.96      0.96     14064\n",
      "\n",
      "Micro-averaged One-vs-Rest ROC AUC score:\n",
      "0.96\n",
      "\n",
      "\n",
      "RobustScaler\n",
      "gen\tnevals\tfitness \tfitness_std\tfitness_max\tfitness_min\n",
      "0  \t50    \t0.929691\t0.0172763  \t0.961942   \t0.898997   \n",
      "1  \t100   \t0.941923\t0.0104872  \t0.958671   \t0.909307   \n",
      "2  \t100   \t0.947791\t0.00873177 \t0.959204   \t0.92719    \n",
      "3  \t100   \t0.947875\t0.00905925 \t0.959204   \t0.920737   \n",
      "4  \t100   \t0.950084\t0.00973363 \t0.959204   \t0.918338   \n",
      "5  \t100   \t0.952298\t0.00758886 \t0.95956    \t0.935207   \n",
      "6  \t100   \t0.948414\t0.0109316  \t0.95956    \t0.919049   \n",
      "7  \t100   \t0.951598\t0.00997287 \t0.959986   \t0.910552   \n",
      "8  \t100   \t0.949463\t0.0140781  \t0.960786   \t0.900188   \n",
      "9  \t100   \t0.95472 \t0.00709335 \t0.961426   \t0.928683   \n",
      "10 \t100   \t0.951164\t0.0131968  \t0.961426   \t0.917431   \n",
      "11 \t100   \t0.952646\t0.0110432  \t0.961337   \t0.919155   \n",
      "12 \t100   \t0.950785\t0.0124646  \t0.961337   \t0.908899   \n",
      "13 \t100   \t0.954763\t0.0101412  \t0.962155   \t0.920417   \n",
      "14 \t100   \t0.956721\t0.00645851 \t0.962155   \t0.927688   \n",
      "15 \t100   \t0.956149\t0.00892288 \t0.962155   \t0.926799   \n",
      "16 \t100   \t0.954204\t0.0133366  \t0.962475   \t0.90881    \n",
      "17 \t100   \t0.95492 \t0.0119724  \t0.962742   \t0.907228   \n",
      "18 \t100   \t0.9532  \t0.0137184  \t0.962742   \t0.907637   \n",
      "19 \t100   \t0.956769\t0.00961093 \t0.962742   \t0.918746   \n",
      "20 \t100   \t0.956665\t0.010817   \t0.962742   \t0.914125   \n",
      "21 \t100   \t0.954261\t0.0136499  \t0.962742   \t0.914125   \n",
      "22 \t100   \t0.956352\t0.0133798  \t0.962333   \t0.901824   \n",
      "best estimator Pipeline(steps=[('scaler', RobustScaler()),\n",
      "                ('estimate', SGDClassifier(alpha=0.1001, early_stopping=True))])\n",
      "\n",
      "Genetic Feature Selection: [ True False False  True  True False False  True False  True False False\n",
      "  True False  True  True  True False False  True  True False  True  True\n",
      "  True  True  True False] \n",
      "\n",
      "classification report \n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Intubation False       0.95      0.97      0.96      6902\n",
      " Intubation True       0.97      0.95      0.96      7162\n",
      "\n",
      "        accuracy                           0.96     14064\n",
      "       macro avg       0.96      0.96      0.96     14064\n",
      "    weighted avg       0.96      0.96      0.96     14064\n",
      "\n",
      "Micro-averaged One-vs-Rest ROC AUC score:\n",
      "0.96\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but GAFeatureSelectionCV was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('### SVM SGDClassifier ###')\n",
    "print()\n",
    "\n",
    "print('SMOTEN median contin')\n",
    "print()\n",
    "\n",
    "print('Genetic Algorithm Feature Selection')\n",
    "smoten_median_imputed_contin = pd.read_csv('smoten_median_imputed_contin.csv', index_col=False)\n",
    "smoten_median_imputed_contin = pd.read_csv('smoten_median_imputed_contin.csv', index_col=False)\n",
    "\n",
    "X = smoten_median_imputed_contin.drop('outcome',axis= 1)\n",
    "y = smoten_median_imputed_contin['outcome']\n",
    "\n",
    "best_paramsS =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.7}\n",
    "best_paramsR =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.1}\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsS['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsS['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'std')\n",
    "\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsR['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsR['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'rbt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b90c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn_genetic import *\n",
    "from sklearn_genetic.space import *\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, RidgeCV, LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "def myGAFeature(X, y, estimate, flag):\n",
    "    \n",
    "    model = lambda aPipe: Pipeline([('scaler',  aPipe), ('estimate', estimate)])\n",
    "    \n",
    "    cv = 2 \n",
    "    top_k = 1\n",
    "    dispatch = '4*n_jobs'\n",
    "    return_train = True\n",
    "    gen = 22\n",
    "    \n",
    "    def analyse(model):\n",
    "        geneSelectFeature = GAFeatureSelectionCV(estimator = model, cv=cv, \n",
    "                                                 scoring=None, population_size=50, \n",
    "                                                 generations=gen, crossover_probability=0.2, \n",
    "                                                 mutation_probability=0.8, tournament_size=3, \n",
    "                                                 elitism=True, max_features=None, verbose=True, \n",
    "                                                 keep_top_k=top_k, criteria='max', \n",
    "                                                 algorithm='eaMuPlusLambda', refit=True, \n",
    "                                                 n_jobs=4, \n",
    "                                                 pre_dispatch=dispatch, error_score=np.nan, \n",
    "                                                 return_train_score=return_train, log_config=None)\n",
    "\n",
    "        geneSelectFeature.fit(X_train, y_train)\n",
    "        y_pred = geneSelectFeature.predict(X_test)\n",
    "        print('best estimator ' + str(geneSelectFeature.best_estimator_))\n",
    "        print()\n",
    "        outcome_labels = ['Intubation False', 'Intubation True']\n",
    "        print('Genetic Feature Selection:', geneSelectFeature.support_, '\\n')\n",
    "        \n",
    "        print('classification report \\n', classification_report(y_test, y_pred, target_names=outcome_labels))\n",
    "        micro_roc_auc_ovr = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=\"micro\")\n",
    "        print(f\"Micro-averaged One-vs-Rest ROC AUC score:\\n{micro_roc_auc_ovr:.2f}\")\n",
    "        print('\\n')\n",
    "        return \"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0) #train split\n",
    "    \n",
    "    if flag == \"std\":\n",
    "        print('StandardScaler')\n",
    "        analyse(model(StandardScaler()))\n",
    "        \n",
    "    elif flag == \"rbt\":\n",
    "        print('RobustScaler')\n",
    "        analyse(model(RobustScaler()))\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1880550e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SVM SGDClassifier ###\n",
      "\n",
      "SGDClassifier all under 40 missing\n",
      "\n",
      "Genetic Algorithm Feature Selection\n",
      "StandardScaler\n",
      "gen\tnevals\tfitness \tfitness_std\tfitness_max\tfitness_min\n",
      "0  \t50    \t0.942175\t0.0136419  \t0.961551   \t0.900011   \n",
      "1  \t100   \t0.952035\t0.00708129 \t0.961551   \t0.936913   \n",
      "2  \t100   \t0.953203\t0.00701882 \t0.962368   \t0.932132   \n",
      "3  \t100   \t0.954384\t0.00801338 \t0.96587    \t0.931705   \n",
      "4  \t100   \t0.953061\t0.00930518 \t0.963844   \t0.931563   \n",
      "5  \t100   \t0.953797\t0.00862968 \t0.963844   \t0.931581   \n",
      "6  \t100   \t0.95528 \t0.00726571 \t0.963133   \t0.933963   \n",
      "7  \t100   \t0.954496\t0.00962022 \t0.964822   \t0.92024    \n",
      "8  \t100   \t0.958655\t0.00757764 \t0.964679   \t0.914302   \n",
      "9  \t100   \t0.956444\t0.0109197  \t0.964679   \t0.918586   \n",
      "10 \t100   \t0.957388\t0.00868889 \t0.964679   \t0.928203   \n",
      "11 \t100   \t0.954501\t0.0122333  \t0.966066   \t0.924986   \n",
      "12 \t100   \t0.953219\t0.0124927  \t0.966066   \t0.912578   \n",
      "13 \t100   \t0.956448\t0.0101584  \t0.966066   \t0.930141   \n",
      "14 \t100   \t0.958555\t0.00849032 \t0.966066   \t0.932612   \n",
      "15 \t100   \t0.95796 \t0.0117123  \t0.964982   \t0.910072   \n",
      "16 \t100   \t0.955693\t0.0152747  \t0.964982   \t0.909503   \n",
      "17 \t100   \t0.959108\t0.00898911 \t0.965515   \t0.925608   \n",
      "18 \t100   \t0.959188\t0.0103756  \t0.965515   \t0.922355   \n",
      "19 \t100   \t0.960286\t0.00803308 \t0.965799   \t0.934211   \n",
      "20 \t100   \t0.960665\t0.00862857 \t0.966013   \t0.932789   \n",
      "21 \t100   \t0.95963 \t0.0116436  \t0.966777   \t0.915991   \n",
      "22 \t100   \t0.961943\t0.00814624 \t0.965906   \t0.931278   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but GAFeatureSelectionCV was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimate',\n",
      "                 SGDClassifier(alpha=0.1001, early_stopping=True, n_jobs=-1,\n",
      "                               validation_fraction=0.9))])\n",
      "\n",
      "Genetic Feature Selection: [ True  True  True  True  True False  True False  True False  True False\n",
      " False  True  True False  True False  True False  True False  True  True\n",
      " False  True  True  True  True  True  True  True False] \n",
      "\n",
      "classification report \n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Intubation False       0.96      0.97      0.97      6902\n",
      " Intubation True       0.98      0.96      0.97      7162\n",
      "\n",
      "        accuracy                           0.97     14064\n",
      "       macro avg       0.97      0.97      0.97     14064\n",
      "    weighted avg       0.97      0.97      0.97     14064\n",
      "\n",
      "Micro-averaged One-vs-Rest ROC AUC score:\n",
      "0.97\n",
      "\n",
      "\n",
      "RobustScaler\n",
      "gen\tnevals\tfitness \tfitness_std\tfitness_max\tfitness_min\n",
      "0  \t50    \t0.941279\t0.0146952  \t0.961711   \t0.89738    \n",
      "1  \t100   \t0.951424\t0.00986555 \t0.962991   \t0.925164   \n",
      "2  \t100   \t0.953093\t0.00858124 \t0.961711   \t0.931918   \n",
      "3  \t100   \t0.955752\t0.00837    \t0.966546   \t0.929448   \n",
      "4  \t100   \t0.955859\t0.00904905 \t0.964786   \t0.923777   \n",
      "5  \t100   \t0.958488\t0.00584301 \t0.964786   \t0.9383     \n",
      "6  \t100   \t0.957321\t0.0104576  \t0.96555    \t0.916133   \n",
      "7  \t100   \t0.956255\t0.0103287  \t0.96555    \t0.91464    \n",
      "8  \t100   \t0.958913\t0.00740497 \t0.96555    \t0.926426   \n",
      "9  \t100   \t0.956272\t0.0127984  \t0.96555    \t0.911014   \n",
      "10 \t100   \t0.957009\t0.0103545  \t0.96555    \t0.918373   \n",
      "11 \t100   \t0.956173\t0.0106409  \t0.964075   \t0.908703   \n",
      "12 \t100   \t0.955669\t0.00962363 \t0.964075   \t0.928505   \n",
      "13 \t100   \t0.958407\t0.00824604 \t0.965337   \t0.923688   \n",
      "14 \t100   \t0.959606\t0.00959041 \t0.964235   \t0.917378   \n",
      "15 \t100   \t0.95587 \t0.0137739  \t0.966101   \t0.902748   \n",
      "16 \t100   \t0.955664\t0.0134842  \t0.966101   \t0.9124     \n",
      "17 \t100   \t0.957758\t0.010808   \t0.965657   \t0.920435   \n",
      "18 \t100   \t0.959008\t0.00893422 \t0.965657   \t0.925466   \n",
      "19 \t100   \t0.957733\t0.0127239  \t0.966741   \t0.907317   \n",
      "20 \t100   \t0.959413\t0.00898057 \t0.965355   \t0.932416   \n",
      "21 \t100   \t0.960103\t0.00847379 \t0.965355   \t0.934051   \n",
      "22 \t100   \t0.955149\t0.0146277  \t0.966137   \t0.90401    \n",
      "best estimator Pipeline(steps=[('scaler', RobustScaler()),\n",
      "                ('estimate',\n",
      "                 SGDClassifier(alpha=0.1001, early_stopping=True, n_jobs=-1,\n",
      "                               validation_fraction=0.5))])\n",
      "\n",
      "Genetic Feature Selection: [ True  True  True False  True False False  True  True False  True  True\n",
      " False  True  True  True  True  True  True  True False  True False  True\n",
      "  True  True  True  True  True False  True  True  True] \n",
      "\n",
      "classification report \n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Intubation False       0.95      0.98      0.96      6902\n",
      " Intubation True       0.98      0.95      0.96      7162\n",
      "\n",
      "        accuracy                           0.96     14064\n",
      "       macro avg       0.96      0.96      0.96     14064\n",
      "    weighted avg       0.96      0.96      0.96     14064\n",
      "\n",
      "Micro-averaged One-vs-Rest ROC AUC score:\n",
      "0.96\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but GAFeatureSelectionCV was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('### SVM SGDClassifier ###')\n",
    "print()\n",
    "\n",
    "print('SGDClassifier all under 40 missing')\n",
    "print()\n",
    "\n",
    "print('Genetic Algorithm Feature Selection')\n",
    "smoten_median_imputed_less_40 = pd.read_csv('smoten_median_imputed_less_40.csv', index_col=False)\n",
    "smoten_median_imputed_less_40 = pd.read_csv('smoten_median_imputed_less_40.csv', index_col=False)\n",
    "\n",
    "X = smoten_median_imputed_less_40.drop('outcome',axis= 1)\n",
    "y = smoten_median_imputed_less_40['outcome']\n",
    "\n",
    "best_paramsS =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.9}\n",
    "best_paramsR =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.5}\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsS['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=-1, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsS['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'std')\n",
    "\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsR['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=-1, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsR['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'rbt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60800a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17b85fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn_genetic import *\n",
    "from sklearn_genetic.space import *\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, RidgeCV, LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "\n",
    "\n",
    "def myGAFeature(X, y, estimate, flag, feature_count):\n",
    "    \n",
    "    model = lambda aPipe: Pipeline([('scaler',  aPipe), ('estimate', estimate)])\n",
    "    \n",
    "    cv = 5 \n",
    "    top_k = 1\n",
    "    dispatch = '4*n_jobs'\n",
    "    return_train = True\n",
    "    gen = 22\n",
    "    \n",
    "    def analyse(model):\n",
    "        SelectFeature = SequentialFeatureSelector(estimator=model, n_features_to_select=feature_count, tol=None, direction='forward', \n",
    "                                                  scoring='f1_micro', cv=cv, n_jobs=None)\n",
    "\n",
    "        SelectFeature.fit(X_train, y_train)\n",
    "        #y_pred = SelectFeature.predict(X_test)\n",
    "        #print('best estimator ' + str(SelectFeature.best_estimator_))\n",
    "        print()\n",
    "        outcome_labels = ['Intubation False', 'Intubation True']\n",
    "        print('Feature Selection:') \n",
    "        features = []\n",
    "        for i in range(len(SelectFeature.feature_names_in_)):\n",
    "            if SelectFeature.support_[i] == True:\n",
    "                features.append(SelectFeature.feature_names_in_[i])\n",
    "        print(features)\n",
    "        print()\n",
    "        #print('classification report \\n', classification_report(y_test, y_pred, target_names=outcome_labels))\n",
    "        #micro_roc_auc_ovr = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=\"micro\")\n",
    "        #print(f\"Micro-averaged One-vs-Rest ROC AUC score:\\n{micro_roc_auc_ovr:.2f}\")\n",
    "        #print('\\n')\n",
    "        return \"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0) #train split\n",
    "    \n",
    "    if flag == \"std\":\n",
    "        print('StandardScaler')\n",
    "        analyse(model(StandardScaler()))\n",
    "        \n",
    "    elif flag == \"rbt\":\n",
    "        print('RobustScaler')\n",
    "        analyse(model(RobustScaler()))\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "afc636d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SVM SGDClassifier ### - SFS Forward\n",
      "\n",
      "SMOTEN median noncontin\n",
      "\n",
      "SFS Feature Selection\n",
      "StandardScaler\n",
      "\n",
      "Feature Selection:\n",
      "['sofa_coagulation', 'sofa_cardiovascular', 'sofa_cns']\n",
      "\n",
      "RobustScaler\n",
      "\n",
      "Feature Selection:\n",
      "['sofa_coagulation', 'sofa_cardiovascular', 'sofa_cns']\n",
      "\n",
      "SMOTEN knn contin\n",
      "\n",
      "SFS Feature Selection\n",
      "StandardScaler\n",
      "\n",
      "Feature Selection:\n",
      "['age', 'heart_rate_mean', 'sbp_mean', 'temperature_mean', 'hemoglobin_max']\n",
      "\n",
      "RobustScaler\n",
      "\n",
      "Feature Selection:\n",
      "['age', 'dbp_mean', 'temperature_mean', 'glucose_max', 'wbc_max']\n",
      "\n",
      "SMOTEN median contin\n",
      "\n",
      "SFS Feature Selection\n",
      "StandardScaler\n",
      "\n",
      "Feature Selection:\n",
      "['age', 'heart_rate_mean', 'dbp_mean', 'temperature_mean', 'hemoglobin_max']\n",
      "\n",
      "RobustScaler\n",
      "\n",
      "Feature Selection:\n",
      "['age', 'dbp_mean', 'temperature_mean', 'glucose_max', 'wbc_max']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nprint('SGDClassifier all under 40 missing')\\nprint()\\n\\nprint('SFS Feature Selection')\\nsmoten_median_imputed_less_40 = pd.read_csv('smoten_median_imputed_less_40.csv', index_col=False)\\nsmoten_median_imputed_less_40 = pd.read_csv('smoten_median_imputed_less_40.csv', index_col=False)\\n\\nX = smoten_median_imputed_less_40.drop('outcome',axis= 1)\\ny = smoten_median_imputed_less_40['outcome']\\n\\nbest_paramsS =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.9}\\nbest_paramsR =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.5}\\n\\nestimate = SGDClassifier(loss='hinge', penalty='l2', \\n                         alpha=best_paramsS['estimate__alpha'], \\n                         l1_ratio=0.15, \\n                         fit_intercept=True, max_iter=1000, \\n                         tol=0.001, shuffle=True, \\n                         verbose=0, epsilon=0.1, \\n                         n_jobs=-1, random_state=None, \\n                         learning_rate='optimal', \\n                         eta0=0.0, power_t=0.5, \\n                         early_stopping=True, \\n                         validation_fraction=best_paramsS['estimate__validation_fraction'], \\n                         n_iter_no_change=5, \\n                         class_weight=None, \\n                         warm_start=False, average=False)\\n\\nmyGAFeature(X, y, estimate, 'std',5)\\n\\n\\nestimate = SGDClassifier(loss='hinge', penalty='l2', \\n                         alpha=best_paramsR['estimate__alpha'], \\n                         l1_ratio=0.15, \\n                         fit_intercept=True, max_iter=1000, \\n                         tol=0.001, shuffle=True, \\n                         verbose=0, epsilon=0.1, \\n                         n_jobs=-1, random_state=None, \\n                         learning_rate='optimal', \\n                         eta0=0.0, power_t=0.5, \\n                         early_stopping=True, \\n                         validation_fraction=best_paramsR['estimate__validation_fraction'], \\n                         n_iter_no_change=5, \\n                         class_weight=None, \\n                         warm_start=False, average=False)\\n\\nmyGAFeature(X, y, estimate, 'rbt',5)\\n\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('### SVM SGDClassifier ### - SFS Forward')\n",
    "print()\n",
    "'''\n",
    "print('SMOTEN median noncontin')\n",
    "print()\n",
    "\n",
    "print('SFS Feature Selection')\n",
    "smoten_noncontin = pd.read_csv('smoten_noncontin.csv', index_col=False)\n",
    "smoten_noncontin = pd.read_csv('smoten_noncontin.csv', index_col=False)\n",
    "\n",
    "X = smoten_noncontin.drop('outcome',axis= 1)\n",
    "y = smoten_noncontin['outcome']\n",
    "\n",
    "\n",
    "best_paramsS =  {'estimate__alpha': 0.2001, 'estimate__validation_fraction': 0.9}\n",
    "best_paramsR =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.1}\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsS['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsS['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'std',3)\n",
    "\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsR['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsR['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'rbt',3)\n",
    "'''\n",
    "\n",
    "print('SMOTEN knn contin')\n",
    "print()\n",
    "\n",
    "print('SFS Feature Selection')\n",
    "smoten_knn_contin = pd.read_csv('smoten_knn_contin.csv', index_col=False).drop(['pt_min','pt_max','urineoutput'],axis=1)\n",
    "\n",
    "X = smoten_knn_contin.drop('outcome',axis= 1)\n",
    "y = smoten_knn_contin['outcome']\n",
    "\n",
    "\n",
    "best_paramsS =  {'estimate__alpha': 0.0001, 'estimate__validation_fraction': 0.1}\n",
    "best_paramsR =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.5}\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsS['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsS['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'std',5)\n",
    "\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsR['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsR['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'rbt',5)\n",
    "\n",
    "\n",
    "\n",
    "print('SMOTEN median contin')\n",
    "print()\n",
    "\n",
    "print('SFS Feature Selection')\n",
    "smoten_median_imputed_contin = pd.read_csv('smoten_median_imputed_contin.csv', index_col=False).drop(['pt_min','pt_max','urineoutput'],axis=1)\n",
    "\n",
    "X = smoten_median_imputed_contin.drop('outcome',axis= 1)\n",
    "y = smoten_median_imputed_contin['outcome']\n",
    "\n",
    "best_paramsS =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.7}\n",
    "best_paramsR =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.1}\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsS['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsS['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'std',5)\n",
    "\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsR['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsR['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'rbt',5)\n",
    "'''\n",
    "print('SGDClassifier all under 40 missing')\n",
    "print()\n",
    "\n",
    "print('SFS Feature Selection')\n",
    "smoten_median_imputed_less_40 = pd.read_csv('smoten_median_imputed_less_40.csv', index_col=False)\n",
    "smoten_median_imputed_less_40 = pd.read_csv('smoten_median_imputed_less_40.csv', index_col=False)\n",
    "\n",
    "X = smoten_median_imputed_less_40.drop('outcome',axis= 1)\n",
    "y = smoten_median_imputed_less_40['outcome']\n",
    "\n",
    "best_paramsS =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.9}\n",
    "best_paramsR =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.5}\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsS['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=-1, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsS['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'std',5)\n",
    "\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsR['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=-1, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsR['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'rbt',5)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c29971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
