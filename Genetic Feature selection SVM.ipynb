{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ac3e891",
   "metadata": {},
   "source": [
    "Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485e7e4f",
   "metadata": {},
   "source": [
    "Genetic Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e98e56e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SVM SGDClassifier ###\n",
      "\n",
      "SMOTEN median noncontin\n",
      "\n",
      "Genetic Algorithm Feature Selection\n",
      "StandardScaler\n",
      "gen\tnevals\tfitness \tfitness_std\tfitness_max\tfitness_min\n",
      "0  \t50    \t0.600015\t0.122764   \t0.695968   \t0.334857   \n",
      "1  \t100   \t0.678345\t0.0553575  \t0.695968   \t0.416458   \n",
      "2  \t100   \t0.671057\t0.0637169  \t0.695968   \t0.416458   \n",
      "3  \t100   \t0.670801\t0.0639475  \t0.695968   \t0.426491   \n",
      "4  \t100   \t0.684979\t0.0446847  \t0.695968   \t0.454232   \n",
      "5  \t100   \t0.677068\t0.0513111  \t0.695968   \t0.526948   \n",
      "6  \t100   \t0.679351\t0.0498932  \t0.695968   \t0.519325   \n",
      "7  \t100   \t0.677737\t0.0494291  \t0.695968   \t0.532096   \n",
      "8  \t100   \t0.680322\t0.0470016  \t0.695968   \t0.530502   \n",
      "9  \t100   \t0.690085\t0.028819   \t0.695968   \t0.548901   \n",
      "10 \t100   \t0.663555\t0.0657085  \t0.695968   \t0.46632    \n",
      "11 \t100   \t0.674824\t0.0524572  \t0.695968   \t0.533384   \n",
      "12 \t100   \t0.683672\t0.0417412  \t0.695968   \t0.533384   \n",
      "13 \t100   \t0.69277 \t0.022386   \t0.695968   \t0.536068   \n",
      "14 \t100   \t0.683149\t0.0435318  \t0.695968   \t0.528348   \n",
      "15 \t100   \t0.690085\t0.028819   \t0.695968   \t0.548901   \n",
      "16 \t100   \t0.689581\t0.0313902  \t0.695968   \t0.523694   \n",
      "17 \t100   \t0.686495\t0.0375444  \t0.695968   \t0.530654   \n",
      "18 \t100   \t0.689692\t0.0308096  \t0.695968   \t0.529227   \n",
      "19 \t100   \t0.680428\t0.0466704  \t0.695968   \t0.534274   \n",
      "20 \t100   \t0.689098\t0.0340149  \t0.695968   \t0.499545   \n",
      "21 \t100   \t0.684202\t0.0398981  \t0.695968   \t0.548901   \n",
      "22 \t100   \t0.680272\t0.0471671  \t0.695968   \t0.526948   \n",
      "23 \t100   \t0.693026\t0.0205893  \t0.695968   \t0.548901   \n",
      "24 \t100   \t0.690085\t0.028819   \t0.695968   \t0.548901   \n",
      "25 \t100   \t0.692687\t0.0229654  \t0.695968   \t0.53193    \n",
      "26 \t100   \t0.683811\t0.0412968  \t0.695968   \t0.529307   \n",
      "27 \t100   \t0.692758\t0.0224716  \t0.695968   \t0.535457   \n",
      "28 \t100   \t0.667212\t0.0615492  \t0.695968   \t0.519723   \n",
      "29 \t100   \t0.670122\t0.0592796  \t0.695968   \t0.526948   \n",
      "30 \t100   \t0.680611\t0.0461029  \t0.695968   \t0.535876   \n",
      "31 \t100   \t0.682726\t0.0458084  \t0.695968   \t0.475055   \n",
      "32 \t100   \t0.687012\t0.0450918  \t0.695968   \t0.420041   \n",
      "33 \t100   \t0.671785\t0.0607457  \t0.695968   \t0.461772   \n",
      "34 \t100   \t0.680856\t0.0524082  \t0.695968   \t0.440624   \n",
      "35 \t100   \t0.685793\t0.0403241  \t0.695968   \t0.51585    \n",
      "36 \t100   \t0.686383\t0.0379387  \t0.695968   \t0.534328   \n",
      "37 \t100   \t0.683259\t0.0431546  \t0.695968   \t0.526948   \n",
      "38 \t100   \t0.68313 \t0.0435958  \t0.695968   \t0.527992   \n",
      "39 \t100   \t0.683215\t0.0432461  \t0.695968   \t0.535415   \n",
      "40 \t100   \t0.692757\t0.0224774  \t0.695968   \t0.535415   \n",
      "best estimator Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimate', SGDClassifier(alpha=0.1001))])\n",
      "\n",
      "Genetic Feature Selection: [False False  True False False False] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but GAFeatureSelectionCV was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16012\\2540973026.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     99\u001b[0m                          warm_start=False, average=False)\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m \u001b[0mmyGAFeature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'std'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16012\\2540973026.py\u001b[0m in \u001b[0;36mmyGAFeature\u001b[1;34m(X, y, estimate, flag)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mflag\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"std\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'StandardScaler'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0manalyse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mflag\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"rbt\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16012\\2540973026.py\u001b[0m in \u001b[0;36manalyse\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0moutcome_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Intubation False'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Intubation True'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Genetic Feature Selection:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgeneSelectFeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names_in_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names_in_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\":\"\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'score \\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgeneSelectFeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn_genetic import *\n",
    "from sklearn_genetic.space import *\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, RidgeCV, LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "def myGAFeature(X, y, estimate, flag):\n",
    "    \n",
    "    model = lambda aPipe: Pipeline([('scaler',  aPipe), ('estimate', estimate)])\n",
    "    \n",
    "    cv = 5 \n",
    "    top_k = 1\n",
    "    dispatch = '8*n_jobs'\n",
    "    return_train = True\n",
    "    gen = 40\n",
    "    \n",
    "    def analyse(model):\n",
    "        geneSelectFeature = GAFeatureSelectionCV(estimator = model, cv=cv, \n",
    "                                                 scoring='f1_weighted', population_size=50, \n",
    "                                                 generations=gen, crossover_probability=0.2, \n",
    "                                                 mutation_probability=0.8, tournament_size=3, \n",
    "                                                 elitism=True, max_features=None, verbose=True, \n",
    "                                                 keep_top_k=top_k, criteria='max', \n",
    "                                                 algorithm='eaMuPlusLambda', refit=True, \n",
    "                                                 n_jobs=4, \n",
    "                                                 pre_dispatch=dispatch, error_score=np.nan, \n",
    "                                                 return_train_score=return_train, log_config=None)\n",
    "\n",
    "        geneSelectFeature.fit(X_train, y_train)\n",
    "        y_pred = geneSelectFeature.predict(X_test)\n",
    "        print('best estimator ' + str(geneSelectFeature.best_estimator_))\n",
    "        print()\n",
    "        outcome_labels = ['Intubation False', 'Intubation True']\n",
    "        print('Genetic Feature Selection:', geneSelectFeature.support_, '\\n')\n",
    "        for i in range(len(clf.feature_names_in_)):\n",
    "            print(clf.feature_names_in_[i], \":\" ,clf[1].feature_importances_[i])\n",
    "            print('score \\n', geneSelectFeature.score(X_train, y_train))\n",
    "            print()\n",
    "        print('classification report \\n', classification_report(y_test, y_pred, target_names=outcome_labels))\n",
    "        micro_roc_auc_ovr = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=\"micro\")\n",
    "        print(f\"Micro-averaged One-vs-Rest ROC AUC score:\\n{micro_roc_auc_ovr:.2f}\")\n",
    "        print('\\n')\n",
    "        return \"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0) #train split\n",
    "    \n",
    "    if flag == \"std\":\n",
    "        print('StandardScaler')\n",
    "        analyse(model(StandardScaler()))\n",
    "        \n",
    "    elif flag == \"rbt\":\n",
    "        print('RobustScaler')\n",
    "        analyse(model(RobustScaler()))\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "print('### SVM SGDClassifier ###')\n",
    "print()\n",
    "\n",
    "print('SMOTEN median noncontin')\n",
    "print()\n",
    "\n",
    "print('Genetic Algorithm Feature Selection')\n",
    "smoten_noncontin = pd.read_csv('smoten_noncontin.csv', index_col=False)\n",
    "smoten_noncontin = pd.read_csv('smoten_noncontin.csv', index_col=False)\n",
    "\n",
    "X = smoten_noncontin.drop('outcome',axis= 1)\n",
    "y = smoten_noncontin['outcome']\n",
    "\n",
    "\n",
    "best_paramsS =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.1}\n",
    "best_paramsR =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.1}\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsS['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=False, \n",
    "                         validation_fraction=best_paramsS['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'std')\n",
    "\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsR['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsR['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'rbt')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dcc993",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('### SVM SGDClassifier ###')\n",
    "print()\n",
    "\n",
    "print('SMOTEN knn contin')\n",
    "print()\n",
    "\n",
    "print('Genetic Algorithm Feature Selection')\n",
    "smoten_knn_contin = pd.read_csv('smoten_knn_contin.csv', index_col=False)\n",
    "smoten_knn_contin = pd.read_csv('smoten_knn_contin.csv', index_col=False)\n",
    "\n",
    "X = smoten_knn_contin.drop('outcome',axis= 1)\n",
    "y = smoten_knn_contin['outcome']\n",
    "\n",
    "\n",
    "best_paramsS =  {'estimate__alpha': 0.0001, 'estimate__validation_fraction': 0.1}\n",
    "best_paramsR =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.5}\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsS['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=False, \n",
    "                         validation_fraction=best_paramsS['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'std')\n",
    "\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsR['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsR['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'rbt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a532bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('### SVM SGDClassifier ###')\n",
    "print()\n",
    "\n",
    "print('SMOTEN median contin')\n",
    "print()\n",
    "\n",
    "print('Genetic Algorithm Feature Selection')\n",
    "smoten_median_imputed_contin = pd.read_csv('smoten_median_imputed_contin.csv', index_col=False)\n",
    "smoten_median_imputed_contin = pd.read_csv('smoten_median_imputed_contin.csv', index_col=False)\n",
    "\n",
    "X = smoten_median_imputed_contin.drop('outcome',axis= 1)\n",
    "y = smoten_median_imputed_contin['outcome']\n",
    "\n",
    "best_paramsS =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.7}\n",
    "best_paramsR =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.1}\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsS['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=False, \n",
    "                         validation_fraction=best_paramsS['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'std')\n",
    "\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsR['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsR['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'rbt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1880550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('### SVM SGDClassifier ###')\n",
    "print()\n",
    "\n",
    "print('SGDClassifier all under 40 missing')\n",
    "print()\n",
    "\n",
    "print('Genetic Algorithm Feature Selection')\n",
    "smoten_median_imputed_contin = pd.read_csv('smoten_median_imputed_contin.csv', index_col=False)\n",
    "smoten_median_imputed_contin = pd.read_csv('smoten_median_imputed_contin.csv', index_col=False)\n",
    "\n",
    "X = smoten_median_imputed_contin.drop('outcome',axis= 1)\n",
    "y = smoten_median_imputed_contin['outcome']\n",
    "\n",
    "best_paramsS =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.9}\n",
    "best_paramsR =  {'estimate__alpha': 0.1001, 'estimate__validation_fraction': 0.5}\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsS['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=False, \n",
    "                         validation_fraction=best_paramsS['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'std')\n",
    "\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                         alpha=best_paramsR['estimate__alpha'], \n",
    "                         l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, \n",
    "                         verbose=0, epsilon=0.1, \n",
    "                         n_jobs=None, random_state=None, \n",
    "                         learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, \n",
    "                         early_stopping=True, \n",
    "                         validation_fraction=best_paramsR['estimate__validation_fraction'], \n",
    "                         n_iter_no_change=5, \n",
    "                         class_weight=None, \n",
    "                         warm_start=False, average=False)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'rbt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
