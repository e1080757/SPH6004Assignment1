{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ac3e891",
   "metadata": {},
   "source": [
    "**SVM non-continuous var**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485e7e4f",
   "metadata": {},
   "source": [
    "genetic opt  noncontin features (SMOTE) and imputed only\n",
    "1_2_1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e98e56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTEN non-contin\n",
      "\n",
      "best_estimator =  Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimate',\n",
      "                 SGDClassifier(alpha=0.2001, early_stopping=True, n_jobs=2,\n",
      "                               validation_fraction=0.9))])\n",
      "best_params =  {'estimate__alpha': 0.2001, 'estimate__validation_fraction': 0.9}\n",
      "best_score =  0.6937508988706119\n",
      "confusion_matrix \n",
      " [[5718 1224]\n",
      " [2940 4182]]\n",
      "Accuracy Score 0.7039249146757679\n",
      "classification_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.82      0.73      6942\n",
      "           1       0.77      0.59      0.67      7122\n",
      "\n",
      "    accuracy                           0.70     14064\n",
      "   macro avg       0.72      0.71      0.70     14064\n",
      "weighted avg       0.72      0.70      0.70     14064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn_genetic import *\n",
    "from sklearn_genetic.space import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, RidgeCV, LassoCV\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, confusion_matrix, roc_auc_score\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, SMOTEN\n",
    "\n",
    "'''\n",
    "param_grid = {\n",
    "    \"clf__n_estimators\": Integer(50, 600),\n",
    "    \"clf__loss\": Categorical([\"absolute_error\", \"squared_error\"]),\n",
    "    \"clf__max_depth\": Integer(2, 10),\n",
    "    \"clf__learning_rate\": Continuous(0.001, 0.01, distribution=\"log-uniform\")}\n",
    "    \n",
    "gaSearch = GASearchCV(estimator=clf, cv=3, \n",
    "            param_grid=param_grid, scoring='accuracy', \n",
    "            population_size=50, generations=80, \n",
    "            crossover_probability=0.2, mutation_probability=0.8, \n",
    "            tournament_size=3, elitism=True, \n",
    "            verbose=True, keep_top_k=1, \n",
    "            criteria='max', algorithm='eaMuPlusLambda', \n",
    "            refit=True, n_jobs=1, \n",
    "            pre_dispatch='4*n_jobs', \n",
    "            error_score=np.nan, return_train_score=False, \n",
    "            log_config=None)\n",
    "\n",
    "gaSearch.fit(X_train, y_train)\n",
    "y_predict_ga = gaSearch.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_predict_ga)\n",
    "\n",
    "'''\n",
    "\n",
    "#'''\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "print('SMOTEN non-contin')\n",
    "print()\n",
    "\n",
    "estimate = SGDClassifier(loss='hinge', penalty='l2', alpha=0.0001, l1_ratio=0.15, \n",
    "                         fit_intercept=True, max_iter=1000, \n",
    "                         tol=0.001, shuffle=True, verbose=0, epsilon=0.1, \n",
    "                         n_jobs=2, random_state=None, learning_rate='optimal', \n",
    "                         eta0=0.0, power_t=0.5, early_stopping=True, \n",
    "                         validation_fraction=0.1, n_iter_no_change=5, \n",
    "                         class_weight=None, warm_start=False, average=False)\n",
    "model = Pipeline([('scaler',  StandardScaler()), ('estimate', estimate)])\n",
    "\n",
    "\n",
    "#cv = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "alpha_lst = [i/10000 for i in range(1,10000,1000)]\n",
    "fraction_lst = [i/10 for i in range(1,10)]\n",
    "\n",
    "param_grid = [{\n",
    "    'estimate__alpha': alpha_lst,\n",
    "    'estimate__validation_fraction': fraction_lst}]\n",
    "\n",
    "\n",
    "#k = 5\n",
    "#kf = KFold(n_splits=k, shuffle=True, random_state=None)\n",
    "\n",
    "#smoten_noncontin = pd.read_csv('smoten_noncontin.csv', index_col=False)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0) #train split\n",
    "\n",
    "smoten_noncontin = pd.read_csv('smoten_noncontin.csv', index_col=False)\n",
    "\n",
    "X = smoten_noncontin.drop('outcome',axis= 1)\n",
    "y = smoten_noncontin['outcome']\n",
    "\n",
    "#acc_score = []\n",
    "#for train_index , test_index in kf.split(X):\n",
    "#    X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "#    y_train , y_test = y[train_index] , y[test_index]\n",
    "    \n",
    "#    model.fit(X_train, y_train)\n",
    "#    y_pred = model.predict(X_test)\n",
    "     \n",
    "#    acc = accuracy_score(y_pred , y_test)\n",
    "#    acc_score.append(acc)\n",
    "     \n",
    "#'''\n",
    "gsSearch = GridSearchCV(estimator=model, param_grid=param_grid, \n",
    "             scoring=['f1_weighted'], n_jobs=2, \n",
    "             refit='f1_weighted', cv=5, \n",
    "             verbose=0, pre_dispatch='4*n_jobs', \n",
    "             error_score=np.nan, return_train_score=False)\n",
    "\n",
    "gsSearch.fit(X_train, y_train)\n",
    "\n",
    "print('best_estimator = ', gsSearch.best_estimator_)\n",
    "best_grid = gsSearch.best_estimator_\n",
    "\n",
    "print('best_params = ', gsSearch.best_params_)\n",
    "print('best_score = ', gsSearch.best_score_)\n",
    "\n",
    "\n",
    "y_pred=best_grid.predict(X_test)\n",
    "print('confusion_matrix \\n', confusion_matrix(y_test,y_pred))\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred)))\n",
    "print('classification_report \\n', classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63207e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf11b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
