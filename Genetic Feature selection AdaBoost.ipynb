{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ac3e891",
   "metadata": {},
   "source": [
    "Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485e7e4f",
   "metadata": {},
   "source": [
    "Genetic Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e98e56e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### AdaBoost ###\n",
      "\n",
      "SMOTEN median noncontin\n",
      "\n",
      "Genetic Algorithm Feature Selection\n",
      "StandardScaler\n",
      "gen\tnevals\tfitness \tfitness_std\tfitness_max\tfitness_min\n",
      "0  \t50    \t0.653332\t0.0642266  \t0.733727   \t0.551147   \n",
      "1  \t100   \t0.705008\t0.0350824  \t0.733727   \t0.585327   \n",
      "2  \t100   \t0.710397\t0.0322794  \t0.733727   \t0.585327   \n",
      "3  \t100   \t0.714169\t0.0256227  \t0.733727   \t0.616736   \n",
      "4  \t100   \t0.719866\t0.0221766  \t0.733727   \t0.580142   \n",
      "5  \t100   \t0.719136\t0.0317584  \t0.733727   \t0.580142   \n",
      "6  \t100   \t0.716661\t0.0406008  \t0.733727   \t0.527786   \n",
      "7  \t100   \t0.707211\t0.0428723  \t0.733727   \t0.575153   \n",
      "8  \t100   \t0.710575\t0.0402033  \t0.733727   \t0.551147   \n",
      "9  \t100   \t0.712426\t0.0345284  \t0.733727   \t0.580142   \n",
      "10 \t100   \t0.70504 \t0.0457927  \t0.733727   \t0.551147   \n",
      "11 \t100   \t0.720862\t0.0244046  \t0.733727   \t0.607468   \n",
      "12 \t100   \t0.714118\t0.0306058  \t0.733727   \t0.598204   \n",
      "13 \t100   \t0.717503\t0.0278014  \t0.733727   \t0.612172   \n",
      "14 \t100   \t0.712678\t0.0394375  \t0.733727   \t0.551147   \n",
      "15 \t100   \t0.716223\t0.0346622  \t0.733727   \t0.596101   \n",
      "16 \t100   \t0.716557\t0.036033   \t0.733727   \t0.586416   \n",
      "17 \t100   \t0.70901 \t0.0462133  \t0.733727   \t0.551147   \n",
      "18 \t100   \t0.717304\t0.0343984  \t0.733727   \t0.580142   \n",
      "19 \t100   \t0.717828\t0.0328952  \t0.733727   \t0.598204   \n",
      "20 \t100   \t0.7114  \t0.045162   \t0.733727   \t0.575153   \n",
      "21 \t100   \t0.721115\t0.0282093  \t0.733727   \t0.598204   \n",
      "22 \t100   \t0.722945\t0.0315229  \t0.733727   \t0.551147   \n",
      "23 \t100   \t0.705013\t0.045323   \t0.733727   \t0.580142   \n",
      "24 \t100   \t0.716451\t0.0343135  \t0.733727   \t0.580142   \n",
      "25 \t100   \t0.711673\t0.0435379  \t0.733727   \t0.551147   \n",
      "26 \t100   \t0.720545\t0.0293336  \t0.733727   \t0.575153   \n",
      "27 \t100   \t0.725719\t0.0223174  \t0.733727   \t0.585374   \n",
      "28 \t100   \t0.72119 \t0.0361743  \t0.733727   \t0.564347   \n",
      "29 \t100   \t0.72071 \t0.031042   \t0.733727   \t0.58421    \n",
      "30 \t100   \t0.725635\t0.0250942  \t0.733727   \t0.564347   \n",
      "31 \t100   \t0.713683\t0.0455024  \t0.733727   \t0.551147   \n",
      "32 \t100   \t0.725131\t0.0201347  \t0.733727   \t0.607468   \n",
      "33 \t100   \t0.722333\t0.0302305  \t0.733727   \t0.526948   \n",
      "34 \t100   \t0.717572\t0.0347134  \t0.733727   \t0.586528   \n",
      "35 \t100   \t0.710898\t0.0363725  \t0.733727   \t0.586416   \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn_genetic import *\n",
    "from sklearn_genetic.space import *\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, RidgeCV, LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "def myGAFeature(X, y, estimate, flag):\n",
    "    \n",
    "    model = lambda aPipe: Pipeline([('scaler',  aPipe), ('estimate', estimate)])\n",
    "    \n",
    "    cv = 5 \n",
    "    top_k = 1\n",
    "    dispatch = '4*n_jobs'\n",
    "    return_train = True\n",
    "    gen = 23\n",
    "    \n",
    "    def analyse(model):\n",
    "        geneSelectFeature = GAFeatureSelectionCV(estimator = model, cv=cv, \n",
    "                                                 scoring='f1_weighted', population_size=50, \n",
    "                                                 generations=gen, crossover_probability=0.2, \n",
    "                                                 mutation_probability=0.8, tournament_size=3, \n",
    "                                                 elitism=True, max_features=None, verbose=True, \n",
    "                                                 keep_top_k=top_k, criteria='max', \n",
    "                                                 algorithm='eaMuPlusLambda', refit=True, \n",
    "                                                 n_jobs=4, \n",
    "                                                 pre_dispatch=dispatch, error_score=np.nan, \n",
    "                                                 return_train_score=return_train, log_config=None)\n",
    "\n",
    "        geneSelectFeature.fit(X_train, y_train)\n",
    "        y_pred = geneSelectFeature.predict(X_test)\n",
    "        print('best estimator ' + str(geneSelectFeature.best_estimator_))\n",
    "        print()\n",
    "        outcome_labels = ['Intubation False', 'Intubation True']\n",
    "        print('Genetic Feature Selection:', geneSelectFeature.support_, '\\n')\n",
    "        for i in range(len(clf.feature_names_in_)):\n",
    "            print(clf.feature_names_in_[i], \":\" ,clf[1].feature_importances_[i])\n",
    "            print('score \\n', geneSelectFeature.score(X_train, y_train))\n",
    "            print()\n",
    "        print('classification report \\n', classification_report(y_test, y_pred, target_names=outcome_labels))\n",
    "        micro_roc_auc_ovr = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=\"micro\")\n",
    "        print(f\"Micro-averaged One-vs-Rest ROC AUC score:\\n{micro_roc_auc_ovr:.2f}\")\n",
    "        print('\\n')\n",
    "        return \"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0) #train split\n",
    "    \n",
    "    if flag == \"std\":\n",
    "        print('StandardScaler')\n",
    "        analyse(model(StandardScaler()))\n",
    "        \n",
    "    elif flag == \"rbt\":\n",
    "        print('RobustScaler')\n",
    "        analyse(model(RobustScaler()))\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "print('### AdaBoost ###')\n",
    "print()\n",
    "\n",
    "print('SMOTEN median noncontin')\n",
    "print()\n",
    "\n",
    "print('Genetic Algorithm Feature Selection')\n",
    "smoten_noncontin = pd.read_csv('smoten_noncontin.csv', index_col=False)\n",
    "\n",
    "\n",
    "X = smoten_noncontin.drop('outcome',axis= 1)\n",
    "y = smoten_noncontin['outcome']\n",
    "\n",
    "\n",
    "best_paramsS =  {'estimate__learning_rate': 0.901}\n",
    "best_paramsR =  {'estimate__learning_rate': 0.901}\n",
    "\n",
    "estimate = AdaBoostClassifier(estimator=None, n_estimators=50, \n",
    "                             learning_rate = best_paramsS['estimate__learning_rate'], algorithm='SAMME.R', \n",
    "                             random_state=None)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'std')\n",
    "\n",
    "estimate = AdaBoostClassifier(estimator=None, n_estimators=50, \n",
    "                             learning_rate = best_paramsR['estimate__learning_rate'], algorithm='SAMME.R', \n",
    "                             random_state=None)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'rbt')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c651d69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Redo with 23 generations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn_genetic import *\n",
    "from sklearn_genetic.space import *\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, RidgeCV, LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "def myGAFeature(X, y, estimate, flag):\n",
    "    \n",
    "    model = lambda aPipe: Pipeline([('scaler',  aPipe), ('estimate', estimate)])\n",
    "    \n",
    "    cv = 5 \n",
    "    top_k = 1\n",
    "    dispatch = '8*n_jobs'\n",
    "    return_train = True\n",
    "    gen = 40\n",
    "    \n",
    "    def analyse(model):\n",
    "        geneSelectFeature = GAFeatureSelectionCV(estimator = model, cv=cv, \n",
    "                                                 scoring='f1_weighted', population_size=50, \n",
    "                                                 generations=gen, crossover_probability=0.2, \n",
    "                                                 mutation_probability=0.8, tournament_size=3, \n",
    "                                                 elitism=True, max_features=None, verbose=True, \n",
    "                                                 keep_top_k=top_k, criteria='max', \n",
    "                                                 algorithm='eaMuPlusLambda', refit=True, \n",
    "                                                 n_jobs=4, \n",
    "                                                 pre_dispatch=dispatch, error_score=np.nan, \n",
    "                                                 return_train_score=return_train, log_config=None)\n",
    "\n",
    "        geneSelectFeature.fit(X_train, y_train)\n",
    "        y_pred = geneSelectFeature.predict(X_test)\n",
    "        print('best estimator ' + str(geneSelectFeature.best_estimator_))\n",
    "        print()\n",
    "        outcome_labels = ['Intubation False', 'Intubation True']\n",
    "        print('Genetic Feature Selection:', geneSelectFeature.support_, '\\n')\n",
    "        for i in range(len(clf.feature_names_in_)):\n",
    "            print(clf.feature_names_in_[i], \":\" ,clf[1].feature_importances_[i])\n",
    "            print('score \\n', geneSelectFeature.score(X_train, y_train))\n",
    "            print()\n",
    "        print('classification report \\n', classification_report(y_test, y_pred, target_names=outcome_labels))\n",
    "        micro_roc_auc_ovr = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=\"micro\")\n",
    "        print(f\"Micro-averaged One-vs-Rest ROC AUC score:\\n{micro_roc_auc_ovr:.2f}\")\n",
    "        print('\\n')\n",
    "        return \"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0) #train split\n",
    "    \n",
    "    if flag == \"std\":\n",
    "        print('StandardScaler')\n",
    "        analyse(model(StandardScaler()))\n",
    "        \n",
    "    elif flag == \"rbt\":\n",
    "        print('RobustScaler')\n",
    "        analyse(model(RobustScaler()))\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "print('### AdaBoost ###')\n",
    "print()\n",
    "\n",
    "print('SMOTEN median noncontin')\n",
    "print()\n",
    "\n",
    "print('Genetic Algorithm Feature Selection')\n",
    "smoten_noncontin = pd.read_csv('smoten_noncontin.csv', index_col=False)\n",
    "\n",
    "\n",
    "X = smoten_noncontin.drop('outcome',axis= 1)\n",
    "y = smoten_noncontin['outcome']\n",
    "\n",
    "\n",
    "best_paramsS =  {'estimate__learning_rate': 0.901}\n",
    "best_paramsR =  {'estimate__learning_rate': 0.901}\n",
    "\n",
    "estimate = AdaBoostClassifier(estimator=None, n_estimators=50, \n",
    "                             learning_rate = best_paramsS['estimate__learning_rate'], algorithm='SAMME.R', \n",
    "                             random_state=None)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'std')\n",
    "\n",
    "estimate = AdaBoostClassifier(estimator=None, n_estimators=50, \n",
    "                             learning_rate = best_paramsR['estimate__learning_rate'], algorithm='SAMME.R', \n",
    "                             random_state=None)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'rbt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dcc993",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('### SVM SGDClassifier ###')\n",
    "print()\n",
    "\n",
    "print('SMOTEN knn contin')\n",
    "print()\n",
    "\n",
    "print('Genetic Algorithm Feature Selection')\n",
    "smoten_knn_contin = pd.read_csv('smoten_knn_contin.csv', index_col=False)\n",
    "\n",
    "\n",
    "X = smoten_knn_contin.drop('outcome',axis= 1)\n",
    "y = smoten_knn_contin['outcome']\n",
    "\n",
    "\n",
    "best_paramsS =  {'estimate__learning_rate': 0.201}\n",
    "best_paramsR =  {'estimate__learning_rate': 0.201}\n",
    "\n",
    "estimate = AdaBoostClassifier(estimator=None, n_estimators=50, \n",
    "                             learning_rate = best_paramsS['estimate__learning_rate'], algorithm='SAMME.R', \n",
    "                             random_state=None)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'std')\n",
    "\n",
    "estimate = AdaBoostClassifier(estimator=None, n_estimators=50, \n",
    "                             learning_rate = best_paramsR['estimate__learning_rate'], algorithm='SAMME.R', \n",
    "                             random_state=None)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'rbt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bacdb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('### SVM SGDClassifier ###')\n",
    "print()\n",
    "\n",
    "print('SMOTEN median contin')\n",
    "print()\n",
    "\n",
    "print('Genetic Algorithm Feature Selection')\n",
    "smoten_median_imputed_contin = pd.read_csv('smoten_median_imputed_contin.csv', index_col=False)\n",
    "\n",
    "X = smoten_median_imputed_contin.drop('outcome',axis= 1)\n",
    "y = smoten_median_imputed_contin['outcome']\n",
    "\n",
    "best_paramsS =  {'estimate__learning_rate': 0.201}\n",
    "best_paramsR =  {'estimate__learning_rate': 0.201}\n",
    "\n",
    "estimate = AdaBoostClassifier(estimator=None, n_estimators=50, \n",
    "                             learning_rate = best_paramsS['estimate__learning_rate'], algorithm='SAMME.R', \n",
    "                             random_state=None)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'std')\n",
    "\n",
    "\n",
    "estimate = mySVC = SVC(kernel='rbf', C=best_paramsR['estimate__C'])\n",
    "\n",
    "myGAFeature(X, y, estimate, 'rbt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb4c542b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFS Forward Feature Selection\n",
      "### Ada Boost ###\n",
      "\n",
      "SMOTEN knn contin\n",
      "\n",
      "SFS Forward Feature Selection\n",
      "StandardScaler\n",
      "\n",
      "Feature Selection:\n",
      "['age', 'mbp_mean', 'dbp_mean', 'temperature_mean', 'wbc_max']\n",
      "\n",
      "RobustScaler\n",
      "\n",
      "Feature Selection:\n",
      "['age', 'mbp_mean', 'dbp_mean', 'temperature_mean', 'wbc_max']\n",
      "\n",
      "### Ada Boost ###\n",
      "\n",
      "SMOTEN median contin\n",
      "\n",
      "SFS Forward Feature Selection\n",
      "StandardScaler\n",
      "\n",
      "Feature Selection:\n",
      "['age', 'mbp_mean', 'temperature_mean', 'wbc_max', 'hemoglobin_max']\n",
      "\n",
      "RobustScaler\n",
      "\n",
      "Feature Selection:\n",
      "['age', 'mbp_mean', 'temperature_mean', 'wbc_max', 'hemoglobin_max']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('SFS Forward Feature Selection')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn_genetic import *\n",
    "from sklearn_genetic.space import *\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, RidgeCV, LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "def myGAFeature(X, y, estimate, flag, feature_count):\n",
    "    \n",
    "    model = lambda aPipe: Pipeline([('scaler',  aPipe), ('estimate', estimate)])\n",
    "    \n",
    "    cv = 2 \n",
    "    top_k = 1\n",
    "    dispatch = '4*n_jobs'\n",
    "    return_train = True\n",
    "    gen = 22\n",
    "    \n",
    "    def analyse(model):\n",
    "        SelectFeature = SequentialFeatureSelector(estimator=model, n_features_to_select=feature_count, tol=None, direction='forward', \n",
    "                                                  scoring='f1_micro', cv=cv, n_jobs=4)\n",
    "\n",
    "        SelectFeature.fit(X_train, y_train)\n",
    "        #y_pred = SelectFeature.predict(X_test)\n",
    "        #print('best estimator ' + str(SelectFeature.best_estimator_))\n",
    "        print()\n",
    "        outcome_labels = ['Intubation False', 'Intubation True']\n",
    "        print('Feature Selection:') \n",
    "        features = []\n",
    "        for i in range(len(SelectFeature.feature_names_in_)):\n",
    "            if SelectFeature.support_[i] == True:\n",
    "                features.append(SelectFeature.feature_names_in_[i])\n",
    "        print(features)\n",
    "        print()\n",
    "        #print('classification report \\n', classification_report(y_test, y_pred, target_names=outcome_labels))\n",
    "        #micro_roc_auc_ovr = roc_auc_score(y_test, y_pred, multi_class=\"ovr\", average=\"micro\")\n",
    "        #print(f\"Micro-averaged One-vs-Rest ROC AUC score:\\n{micro_roc_auc_ovr:.2f}\")\n",
    "        #print('\\n')\n",
    "        return \"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0) #train split\n",
    "    \n",
    "    if flag == \"std\":\n",
    "        print('StandardScaler')\n",
    "        analyse(model(StandardScaler()))\n",
    "        \n",
    "    elif flag == \"rbt\":\n",
    "        print('RobustScaler')\n",
    "        analyse(model(RobustScaler()))\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "\n",
    "print('### Ada Boost ###')\n",
    "print()\n",
    "\n",
    "print('SMOTEN knn contin')\n",
    "print()\n",
    "\n",
    "print('SFS Forward Feature Selection')\n",
    "smoten_knn_contin = pd.read_csv('smoten_knn_contin.csv', index_col=False).drop(['pt_min','pt_max','urineoutput'],axis=1)\n",
    "\n",
    "\n",
    "X = smoten_knn_contin.drop('outcome',axis= 1)\n",
    "y = smoten_knn_contin['outcome']\n",
    "\n",
    "\n",
    "best_paramsS =  {'estimate__learning_rate': 0.201}\n",
    "best_paramsR =  {'estimate__learning_rate': 0.201}\n",
    "\n",
    "estimate = AdaBoostClassifier(estimator=None, n_estimators=50, \n",
    "                             learning_rate = best_paramsS['estimate__learning_rate'], algorithm='SAMME.R', \n",
    "                             random_state=None)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'std',5)\n",
    "\n",
    "estimate = AdaBoostClassifier(estimator=None, n_estimators=50, \n",
    "                             learning_rate = best_paramsR['estimate__learning_rate'], algorithm='SAMME.R', \n",
    "                             random_state=None)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'rbt',5)\n",
    "\n",
    "print('### Ada Boost ###')\n",
    "print()\n",
    "\n",
    "print('SMOTEN median contin')\n",
    "print()\n",
    "\n",
    "print('SFS Forward Feature Selection')\n",
    "smoten_median_imputed_contin = pd.read_csv('smoten_median_imputed_contin.csv', index_col=False).drop(['pt_min','pt_max','urineoutput'],axis=1)\n",
    "\n",
    "X = smoten_median_imputed_contin.drop('outcome',axis= 1)\n",
    "y = smoten_median_imputed_contin['outcome']\n",
    "\n",
    "best_paramsS =  {'estimate__learning_rate': 0.201}\n",
    "best_paramsR =  {'estimate__learning_rate': 0.201}\n",
    "\n",
    "estimate = AdaBoostClassifier(estimator=None, n_estimators=50, \n",
    "                             learning_rate = best_paramsS['estimate__learning_rate'], algorithm='SAMME.R', \n",
    "                             random_state=None)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'std',5)\n",
    "\n",
    "estimate = AdaBoostClassifier(estimator=None, n_estimators=50, \n",
    "                             learning_rate = best_paramsR['estimate__learning_rate'], algorithm='SAMME.R', \n",
    "                             random_state=None)\n",
    "myGAFeature(X, y, estimate, 'rbt',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e431f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('### SVM SGDClassifier ###')\n",
    "print()\n",
    "\n",
    "print('SGDClassifier all under 40 missing')\n",
    "print()\n",
    "\n",
    "print('Genetic Algorithm Feature Selection')\n",
    "smoten_median_imputed_contin = pd.read_csv('smoten_median_imputed_contin.csv', index_col=False)\n",
    "\n",
    "\n",
    "X = smoten_median_imputed_contin.drop('outcome',axis= 1)\n",
    "y = smoten_median_imputed_contin['outcome']\n",
    "\n",
    "best_paramsS =  {'estimate__learning_rate': 0.201}\n",
    "best_paramsR =  {'estimate__learning_rate': 0.201}\n",
    "\n",
    "estimate = AdaBoostClassifier(estimator=None, n_estimators=50, \n",
    "                             learning_rate = best_paramsS['estimate__learning_rate'], algorithm='SAMME.R', \n",
    "                             random_state=None)\n",
    "\n",
    "myGAFeature(X, y, estimate, 'std')\n",
    "\n",
    "\n",
    "estimate = mySVC = SVC(kernel='rbf', C=best_paramsR['estimate__C'])\n",
    "\n",
    "myGAFeature(X, y, estimate, 'rbt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb00341a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
