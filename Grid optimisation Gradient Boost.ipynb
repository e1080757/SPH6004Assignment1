{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ac3e891",
   "metadata": {},
   "source": [
    "Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485e7e4f",
   "metadata": {},
   "source": [
    "Genetic Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde7c497",
   "metadata": {},
   "source": [
    "Grid optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e98e56e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Gradient Boost SMOTEN median noncontin ###\n",
      "\n",
      "Gradient Boost\n",
      "\n",
      "StandardScaler\n",
      "best_estimator =  Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimate',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0,\n",
      "                                            n_estimators=150))])\n",
      "best_params =  {'estimate__learning_rate': 1.0, 'estimate__n_estimators': 150}\n",
      "best_score =  0.8011478433550746\n",
      "confusion_matrix \n",
      " [[5510 1392]\n",
      " [1421 5741]]\n",
      "Accuracy Score 0.799985779294653\n",
      "classification_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      6902\n",
      "           1       0.80      0.80      0.80      7162\n",
      "\n",
      "    accuracy                           0.80     14064\n",
      "   macro avg       0.80      0.80      0.80     14064\n",
      "weighted avg       0.80      0.80      0.80     14064\n",
      "\n",
      "RobustScaler\n",
      "best_estimator =  Pipeline(steps=[('scaler', RobustScaler()),\n",
      "                ('estimate',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0,\n",
      "                                            n_estimators=150))])\n",
      "best_params =  {'estimate__learning_rate': 1.0, 'estimate__n_estimators': 150}\n",
      "best_score =  0.8011478433550746\n",
      "confusion_matrix \n",
      " [[5510 1392]\n",
      " [1421 5741]]\n",
      "Accuracy Score 0.799985779294653\n",
      "classification_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      6902\n",
      "           1       0.80      0.80      0.80      7162\n",
      "\n",
      "    accuracy                           0.80     14064\n",
      "   macro avg       0.80      0.80      0.80     14064\n",
      "weighted avg       0.80      0.80      0.80     14064\n",
      "\n",
      "### Gradient Boost SMOTEN knn contin ###\n",
      "\n",
      "Gradient Boost\n",
      "\n",
      "StandardScaler\n",
      "best_estimator =  Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimate', GradientBoostingClassifier(n_estimators=150))])\n",
      "best_params =  {'estimate__learning_rate': 0.1, 'estimate__n_estimators': 150}\n",
      "best_score =  0.975766336078246\n",
      "confusion_matrix \n",
      " [[6819   83]\n",
      " [ 271 6891]]\n",
      "Accuracy Score 0.9748293515358362\n",
      "classification_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      6902\n",
      "           1       0.99      0.96      0.97      7162\n",
      "\n",
      "    accuracy                           0.97     14064\n",
      "   macro avg       0.97      0.98      0.97     14064\n",
      "weighted avg       0.98      0.97      0.97     14064\n",
      "\n",
      "RobustScaler\n",
      "best_estimator =  Pipeline(steps=[('scaler', RobustScaler()),\n",
      "                ('estimate', GradientBoostingClassifier(n_estimators=150))])\n",
      "best_params =  {'estimate__learning_rate': 0.1, 'estimate__n_estimators': 150}\n",
      "best_score =  0.9757841037682267\n",
      "confusion_matrix \n",
      " [[6819   83]\n",
      " [ 272 6890]]\n",
      "Accuracy Score 0.9747582480091013\n",
      "classification_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      6902\n",
      "           1       0.99      0.96      0.97      7162\n",
      "\n",
      "    accuracy                           0.97     14064\n",
      "   macro avg       0.97      0.97      0.97     14064\n",
      "weighted avg       0.98      0.97      0.97     14064\n",
      "\n",
      "### Gradient Boost SMOTEN median contin ###\n",
      "\n",
      "Gradient Boost\n",
      "\n",
      "StandardScaler\n",
      "best_estimator =  Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimate', GradientBoostingClassifier(n_estimators=150))])\n",
      "best_params =  {'estimate__learning_rate': 0.1, 'estimate__n_estimators': 150}\n",
      "best_score =  0.9759795382248043\n",
      "confusion_matrix \n",
      " [[6822   80]\n",
      " [ 275 6887]]\n",
      "Accuracy Score 0.9747582480091013\n",
      "classification_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      6902\n",
      "           1       0.99      0.96      0.97      7162\n",
      "\n",
      "    accuracy                           0.97     14064\n",
      "   macro avg       0.97      0.98      0.97     14064\n",
      "weighted avg       0.98      0.97      0.97     14064\n",
      "\n",
      "RobustScaler\n",
      "best_estimator =  Pipeline(steps=[('scaler', RobustScaler()),\n",
      "                ('estimate', GradientBoostingClassifier(n_estimators=150))])\n",
      "best_params =  {'estimate__learning_rate': 0.1, 'estimate__n_estimators': 150}\n",
      "best_score =  0.9759440022006997\n",
      "confusion_matrix \n",
      " [[6821   81]\n",
      " [ 275 6887]]\n",
      "Accuracy Score 0.9746871444823664\n",
      "classification_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      6902\n",
      "           1       0.99      0.96      0.97      7162\n",
      "\n",
      "    accuracy                           0.97     14064\n",
      "   macro avg       0.97      0.97      0.97     14064\n",
      "weighted avg       0.98      0.97      0.97     14064\n",
      "\n",
      "### Gradient Boost SMOTEN all under 40 missing ###\n",
      "\n",
      "Gradient Boost\n",
      "\n",
      "StandardScaler\n",
      "best_estimator =  Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimate', GradientBoostingClassifier(n_estimators=150))])\n",
      "best_params =  {'estimate__learning_rate': 0.1, 'estimate__n_estimators': 150}\n",
      "best_score =  0.9769749673100347\n",
      "confusion_matrix \n",
      " [[6816   86]\n",
      " [ 269 6893]]\n",
      "Accuracy Score 0.9747582480091013\n",
      "classification_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      6902\n",
      "           1       0.99      0.96      0.97      7162\n",
      "\n",
      "    accuracy                           0.97     14064\n",
      "   macro avg       0.97      0.97      0.97     14064\n",
      "weighted avg       0.98      0.97      0.97     14064\n",
      "\n",
      "RobustScaler\n",
      "best_estimator =  Pipeline(steps=[('scaler', RobustScaler()),\n",
      "                ('estimate', GradientBoostingClassifier(n_estimators=150))])\n",
      "best_params =  {'estimate__learning_rate': 0.1, 'estimate__n_estimators': 150}\n",
      "best_score =  0.9770460393816203\n",
      "confusion_matrix \n",
      " [[6817   85]\n",
      " [ 269 6893]]\n",
      "Accuracy Score 0.9748293515358362\n",
      "classification_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      6902\n",
      "           1       0.99      0.96      0.97      7162\n",
      "\n",
      "    accuracy                           0.97     14064\n",
      "   macro avg       0.97      0.98      0.97     14064\n",
      "weighted avg       0.98      0.97      0.97     14064\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn_genetic import *\n",
    "from sklearn_genetic.space import *\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, RidgeCV, LassoCV, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "def myGrid(X, y, estimate, param):\n",
    "    \n",
    "    model = lambda aPipe: Pipeline([('scaler',  aPipe), ('estimate', estimate)]) \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0) #train split\n",
    "    \n",
    "    def analyse(model, param_grid):\n",
    "        gsSearch = GridSearchCV(estimator=model, param_grid=param_grid, \n",
    "                 scoring=['f1_weighted'], n_jobs=4, \n",
    "                 refit='f1_weighted', cv=5, \n",
    "                 verbose=0, pre_dispatch='8*n_jobs', \n",
    "                 error_score=np.nan, return_train_score=False)\n",
    "\n",
    "        acc_score = []\n",
    "        gsSearch.fit(X_train, y_train)\n",
    "        y_pred = gsSearch.predict(X_test)\n",
    "        acc = accuracy_score(y_pred , y_test)\n",
    "        acc_score.append(acc)\n",
    "        \n",
    "        print('best_estimator = ', gsSearch.best_estimator_)\n",
    "        best_grid = gsSearch.best_estimator_\n",
    "        print('best_params = ', gsSearch.best_params_)\n",
    "        print('best_score = ', gsSearch.best_score_)\n",
    "        y_pred=best_grid.predict(X_test)\n",
    "        print('confusion_matrix \\n', confusion_matrix(y_test,y_pred))\n",
    "        print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred)))\n",
    "        print('classification_report \\n', classification_report(y_test,y_pred))\n",
    "        return \"\"\n",
    "    \n",
    "    print('StandardScaler')\n",
    "    analyse(model(StandardScaler()), param)\n",
    "    print('RobustScaler')\n",
    "    analyse(model(RobustScaler()), param)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "\n",
    "print('### Gradient Boost SMOTEN median noncontin ###')\n",
    "print()\n",
    "\n",
    "smoten_noncontin = pd.read_csv('smoten_noncontin.csv', index_col=False)\n",
    "\n",
    "X = smoten_noncontin.drop('outcome',axis= 1)\n",
    "y = smoten_noncontin['outcome']\n",
    "\n",
    "print('Gradient Boost')\n",
    "print()\n",
    "\n",
    "learning_rate_lst = [i/10 for i in range(1,11)]\n",
    "n_estimators_lst = [50, 100, 150]\n",
    "param_grid = [{\n",
    "    'estimate__learning_rate': learning_rate_lst,\n",
    "    'estimate__n_estimators': n_estimators_lst}]\n",
    "\n",
    "model = GradientBoostingClassifier(loss='log_loss', \n",
    "                                      subsample=1.0, \n",
    "                                      criterion='friedman_mse', min_samples_split=2, \n",
    "                                      min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
    "                                      max_depth=3, min_impurity_decrease=0.0, init=None, \n",
    "                                      random_state=None, max_features=None, verbose=0, \n",
    "                                      max_leaf_nodes=None, warm_start=False, \n",
    "                                      validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "\n",
    "myGrid(X, y, model, param_grid)\n",
    "\n",
    "\n",
    "\n",
    "print('### Gradient Boost SMOTEN knn contin ###')\n",
    "print()\n",
    "\n",
    "smoten_knn_contin = pd.read_csv('smoten_knn_contin.csv', index_col=False)\n",
    "\n",
    "X = smoten_knn_contin.drop('outcome',axis= 1)\n",
    "y = smoten_knn_contin['outcome']\n",
    "\n",
    "print('Gradient Boost')\n",
    "print()\n",
    "\n",
    "learning_rate_lst = [i/10 for i in range(1,11)]\n",
    "n_estimators_lst = [50, 100, 150]\n",
    "param_grid = [{\n",
    "    'estimate__learning_rate': learning_rate_lst,\n",
    "    'estimate__n_estimators': n_estimators_lst}]\n",
    "\n",
    "model = GradientBoostingClassifier(loss='log_loss', \n",
    "                                      subsample=1.0, \n",
    "                                      criterion='friedman_mse', min_samples_split=2, \n",
    "                                      min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
    "                                      max_depth=3, min_impurity_decrease=0.0, init=None, \n",
    "                                      random_state=None, max_features=None, verbose=0, \n",
    "                                      max_leaf_nodes=None, warm_start=False, \n",
    "                                      validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "\n",
    "myGrid(X, y, model, param_grid)\n",
    "\n",
    "\n",
    "print('### Gradient Boost SMOTEN median contin ###')\n",
    "print()\n",
    "\n",
    "\n",
    "smoten_median_imputed_contin = pd.read_csv('smoten_median_imputed_contin.csv', index_col=False)\n",
    "\n",
    "X = smoten_median_imputed_contin.drop('outcome',axis= 1)\n",
    "y = smoten_median_imputed_contin['outcome']\n",
    "\n",
    "print('Gradient Boost')\n",
    "print()\n",
    "\n",
    "learning_rate_lst = [i/10 for i in range(1,11)]\n",
    "n_estimators_lst = [50, 100, 150]\n",
    "param_grid = [{\n",
    "    'estimate__learning_rate': learning_rate_lst,\n",
    "    'estimate__n_estimators': n_estimators_lst}]\n",
    "\n",
    "model = GradientBoostingClassifier(loss='log_loss', \n",
    "                                      subsample=1.0, \n",
    "                                      criterion='friedman_mse', min_samples_split=2, \n",
    "                                      min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
    "                                      max_depth=3, min_impurity_decrease=0.0, init=None, \n",
    "                                      random_state=None, max_features=None, verbose=0, \n",
    "                                      max_leaf_nodes=None, warm_start=False, \n",
    "                                      validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "\n",
    "\n",
    "myGrid(X, y, model, param_grid)\n",
    "\n",
    "\n",
    "print('### Gradient Boost SMOTEN all under 40 missing ###')\n",
    "print()\n",
    "\n",
    "smoten_median_imputed_less_40 = pd.read_csv('smoten_median_imputed_less_40.csv', index_col=False)\n",
    "\n",
    "X = smoten_median_imputed_less_40.drop('outcome',axis= 1)\n",
    "y = smoten_median_imputed_less_40['outcome']\n",
    "\n",
    "print('Gradient Boost')\n",
    "print()\n",
    "\n",
    "learning_rate_lst = [i/10 for i in range(1,11)]\n",
    "n_estimators_lst = [50, 100, 150]\n",
    "param_grid = [{\n",
    "    'estimate__learning_rate': learning_rate_lst,\n",
    "    'estimate__n_estimators': n_estimators_lst}]\n",
    "\n",
    "model = GradientBoostingClassifier(loss='log_loss', \n",
    "                                      subsample=1.0, \n",
    "                                      criterion='friedman_mse', min_samples_split=2, \n",
    "                                      min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
    "                                      max_depth=3, min_impurity_decrease=0.0, init=None, \n",
    "                                      random_state=None, max_features=None, verbose=0, \n",
    "                                      max_leaf_nodes=None, warm_start=False, \n",
    "                                      validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "\n",
    "\n",
    "myGrid(X, y, model, param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dcc993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
